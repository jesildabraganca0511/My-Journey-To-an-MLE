{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eb07f1",
   "metadata": {},
   "source": [
    "Exercise 1: Model Prediction Validator (20 min)\n",
    "Scenario: Your ML model returns predictions, but sometimes they're invalid. Build a validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ef3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_id': 'U001', 'age': 25, 'revenue': 150.5, 'country': 'US'}]\n",
      "[{'user_id': 'U002', 'age': -5, 'revenue': 200.0, 'country': 'UK'}, {'user_id': 'U003', 'age': 30, 'revenue': 'invalid', 'country': 'CA'}, {'user_id': '', 'age': 28, 'revenue': 175.25, 'country': 'US'}, {'user_id': 'U005', 'age': 150, 'revenue': 99.99, 'country': ''}]\n",
      "5\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# You receive predictions from your model like this:\n",
    "predictions = [\n",
    "    {\"model_id\": \"v1.2\", \"prediction\": 0.85, \"confidence\": 0.92},\n",
    "    {\"model_id\": \"v1.2\", \"prediction\": 1.5, \"confidence\": 0.88},   # Invalid: > 1.0\n",
    "    {\"model_id\": \"v1.2\", \"prediction\": -0.1, \"confidence\": 0.75},  # Invalid: < 0.0\n",
    "    {\"model_id\": \"v1.2\", \"prediction\": 0.65, \"confidence\": 1.2},   # Invalid confidence\n",
    "    {\"model_id\": \"v1.2\", \"prediction\": 0.45, \"confidence\": 0.81},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# For each prediction, check:\n",
    "# 1. prediction is between 0.0 and 1.0 (inclusive)\n",
    "# 2. confidence is between 0.0 and 1.0 (inclusive)\n",
    "# 3. Both are numbers (float or int)\n",
    "#\n",
    "# Create two lists:\n",
    "# - valid_predictions: predictions that pass all checks\n",
    "# - invalid_predictions: predictions that fail (include which check failed)\n",
    "#\n",
    "# Print summary:\n",
    "# \"Total predictions: 5\"\n",
    "# \"Valid: 2\"\n",
    "# \"Invalid: 3\"\n",
    "# \"Invalid reasons: {'prediction_out_of_range': 2, 'confidence_out_of_range': 1}\"\n",
    "\n",
    "# STARTER CODE:\n",
    "valid_predictions = []\n",
    "invalid_predictions = []\n",
    "\n",
    "for pred in predictions:\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total predictions: {len(predictions)}\")\n",
    "# ... continue\n",
    "```\n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "Total predictions: 5\n",
    "Valid: 2\n",
    "Invalid: 3\n",
    "Invalid reasons: {'prediction_out_of_range': 2, 'confidence_out_of_range': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620887e",
   "metadata": {},
   "source": [
    "Exercise 2: Training Data Categorizer (25 min)\n",
    "Scenario: Categorize training samples based on their labels and confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf253a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2026-01-26', '09:15:23', 'INFO', 'Model training started']\n",
      "['2026-01-26', '09:16:45', 'ERROR', 'Failed to load dataset: FileNotFoundError']\n",
      "['2026-01-26', '09:17:12', 'WARNING', 'Low memory: 85% used']\n",
      "['2026-01-26', '09:18:33', 'INFO', 'Epoch 1/10 completed']\n",
      "['2026-01-26', '09:19:44', 'ERROR', 'CUDA out of memory']\n",
      "['2026-01-26', '09:20:15', 'ERROR', 'Failed to load dataset: FileNotFoundError']\n",
      "['2026-01-26', '09:21:05', 'INFO', 'Model saved successfully']\n",
      "['2026-01-26', '09:22:18', 'WARNING', 'Validation accuracy below threshold']\n",
      "['09:15:23', '09:16:45', '09:17:12', '09:18:33', '09:19:44', '09:20:15', '09:21:05', '09:22:18']\n",
      "['INFO', 'ERROR', 'WARNING', 'INFO', 'ERROR', 'ERROR', 'INFO', 'WARNING']\n",
      "['Model training started', 'Failed to load dataset: FileNotFoundError', 'Low memory: 85% used', 'Epoch 1/10 completed', 'CUDA out of memory', 'Failed to load dataset: FileNotFoundError', 'Model saved successfully', 'Validation accuracy below threshold']\n"
     ]
    }
   ],
   "source": [
    "# Training samples with human-labeled confidence\n",
    "samples = [\n",
    "    {\"id\": 1, \"label\": \"spam\", \"confidence\": \"high\", \"text_length\": 150},\n",
    "    {\"id\": 2, \"label\": \"ham\", \"confidence\": \"medium\", \"text_length\": 80},\n",
    "    {\"id\": 3, \"label\": \"spam\", \"confidence\": \"low\", \"text_length\": 200},\n",
    "    {\"id\": 4, \"label\": \"spam\", \"confidence\": \"high\", \"text_length\": 120},\n",
    "    {\"id\": 5, \"label\": \"ham\", \"confidence\": \"high\", \"text_length\": 95},\n",
    "    {\"id\": 6, \"label\": \"spam\", \"confidence\": \"medium\", \"text_length\": 175},\n",
    "    {\"id\": 7, \"label\": \"ham\", \"confidence\": \"low\", \"text_length\": 60},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Count how many samples per label (spam vs ham)\n",
    "# 2. Count how many per confidence level (high, medium, low)\n",
    "# 3. Find samples that are:\n",
    "#    - spam AND high confidence\n",
    "#    - ham AND low confidence (these might need review)\n",
    "# 4. Calculate average text_length for spam vs ham\n",
    "#\n",
    "# Use if/elif/else and comparison operators\n",
    "\n",
    "# Expected output structure:\n",
    "# Label counts: spam=4, ham=3\n",
    "# Confidence counts: high=3, medium=2, low=2\n",
    "# High confidence spam: 2 samples (IDs: 1, 4)\n",
    "# Low confidence ham: 1 sample (IDs: 7) <- might need review\n",
    "# Avg length - spam: 161.25, ham: 78.33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872cf64",
   "metadata": {},
   "source": [
    "EXERCISE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f3f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Config invalid:\n"
     ]
    }
   ],
   "source": [
    "# This simulates a config file (later you'll read from JSON/YAML)\n",
    "training_config1 = {\n",
    "    \"model_name\": \"resnet50\",\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 100,\n",
    "    \"gpu_id\": 0,\n",
    "    \"data_path\": \"/data/imagenet\",\n",
    "    \"save_checkpoints\": True,\n",
    "}\n",
    "\n",
    "# Validation rules (your manager gives you these):\n",
    "VALID_MODELS = [\"resnet50\", \"vgg16\", \"efficientnet\"]\n",
    "MIN_BATCH_SIZE = 1\n",
    "MAX_BATCH_SIZE = 512\n",
    "MIN_LR = 0.00001\n",
    "MAX_LR = 1.0\n",
    "MIN_EPOCHS = 1\n",
    "MAX_EPOCHS = 1000\n",
    "\n",
    "\n",
    "# 2. If ALL valid: print \"✓ Config valid. Safe to start training.\"\n",
    "# 3. If ANY invalid: print \"✗ Config invalid:\" and list ALL issues\n",
    "#    Example: \"✗ Config invalid:\n",
    "#             - batch_size 1024 exceeds maximum 512\n",
    "#             - learning_rate 5.0 exceeds maximum 1.0\"\n",
    "#\n",
    "# 3. Test with INVALID config:\n",
    "training_config = {\n",
    "    \"model_name\": \"bert\",  # Not in valid models\n",
    "    \"batch_size\": 1024,    # Too large\n",
    "    \"learning_rate\": 5.0,  # Too large\n",
    "    \"epochs\": -10,         # Negative\n",
    "    \"gpu_id\": -1,          # Negative\n",
    "    \"data_path\": \"\",       # Empty\n",
    "    \"save_checkpoints\": \"yes\",  # Wrong type\n",
    "}\n",
    "\n",
    "# Your job:\n",
    "# 1. Check:\n",
    "#    - model_name is in VALID_MODELS\n",
    "#    - batch_size is between MIN and MAX\n",
    "#    - learning_rate is between MIN and MAX\n",
    "#    - epochs is between MIN and MAX\n",
    "#    - gpu_id is 0 or positi\n",
    "#    - data_path is not empty string\n",
    "#    - save_checkpoints is True or False (boolean)\n",
    "if training_config['model_name'] in VALID_MODELS and MIN_BATCH_SIZE<=training_config[\"batch_size\"]<=MAX_BATCH_SIZE and MIN_LR<=training_config[\"learning_rate\"]<=MAX_LR and MIN_EPOCHS<=training_config[\"epochs\"]<=MAX_EPOCHS and training_config['gpu_id'] >=0 and training_config['data_path']!= \"\" and (training_config['save_checkpoints'] ==True or training_config['save_checkpoints'] ==False):\n",
    "    print('✓ Config valid. Safe to start training.')\n",
    "else:\n",
    "    print('✗ Config invalid:')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eba88",
   "metadata": {},
   "source": [
    "Exercise 3: Feature Threshold Filter (30 min)\n",
    "Scenario: Your feature engineering pipeline needs to filter data based on multiple conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw features extracted from text\n",
    "features = [\n",
    "    {\"doc_id\": \"D001\", \"word_count\": 500, \"avg_word_len\": 5.2, \"sentiment\": 0.8, \"has_urls\": True},\n",
    "    {\"doc_id\": \"D002\", \"word_count\": 50, \"avg_word_len\": 3.1, \"sentiment\": -0.3, \"has_urls\": False},\n",
    "    {\"doc_id\": \"D003\", \"word_count\": 1200, \"avg_word_len\": 6.8, \"sentiment\": 0.5, \"has_urls\": True},\n",
    "    {\"doc_id\": \"D004\", \"word_count\": 300, \"avg_word_len\": 4.5, \"sentiment\": -0.9, \"has_urls\": False},\n",
    "    {\"doc_id\": \"D005\", \"word_count\": 80, \"avg_word_len\": 2.8, \"sentiment\": 0.1, \"has_urls\": True},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# Filter documents into categories based on these rules:\n",
    "#\n",
    "# \"high_quality\":\n",
    "#   - word_count >= 200\n",
    "#   - avg_word_len >= 4.0\n",
    "#   - sentiment > 0.3\n",
    "#\n",
    "# \"low_quality\":\n",
    "#   - word_count < 100\n",
    "#   - OR avg_word_len < 3.5\n",
    "#   - OR sentiment < -0.5\n",
    "#\n",
    "# \"needs_review\":\n",
    "#   - Everything else\n",
    "#\n",
    "# Also create a separate list of docs with URLs (might be spam)\n",
    "#\n",
    "# Output:\n",
    "# High quality: 2 docs (D001, D003)\n",
    "# Low quality: 2 docs (D002, D004)\n",
    "# Needs review: 1 doc (D005)\n",
    "# Contains URLs: 3 docs (D001, D003, D005)\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "high_quality = []\n",
    "low_quality = []\n",
    "needs_review = []\n",
    "has_urls = []\n",
    "\n",
    "for doc in features:\n",
    "    # Categorize each document\n",
    "    # Hint: Check high_quality first, then low_quality, else needs_review\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate errors collected from monitoring system\n",
    "errors = [\n",
    "    {\"timestamp\": \"2026-01-26 02:15:33\", \"component\": \"data_loader\", \n",
    "     \"error_type\": \"FileNotFoundError\", \"severity\": \"HIGH\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 02:16:45\", \"component\": \"model_inference\", \n",
    "     \"error_type\": \"CUDA_OUT_OF_MEMORY\", \"severity\": \"CRITICAL\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 02:17:12\", \"component\": \"data_loader\", \n",
    "     \"error_type\": \"FileNotFoundError\", \"severity\": \"HIGH\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 03:22:05\", \"component\": \"api_server\", \n",
    "     \"error_type\": \"TimeoutError\", \"severity\": \"MEDIUM\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 03:45:18\", \"component\": \"model_inference\", \n",
    "     \"error_type\": \"InvalidInputShape\", \"severity\": \"HIGH\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 04:10:33\", \"component\": \"data_loader\", \n",
    "     \"error_type\": \"FileNotFoundError\", \"severity\": \"HIGH\"},\n",
    "]\n",
    "\n",
    "# Generate report:\n",
    "\"\"\"\n",
    "=== OVERNIGHT ERROR REPORT ===\n",
    "Time range: 02:15:33 - 04:10:33\n",
    "Total errors: 6\n",
    "\n",
    "By Severity:\n",
    "  CRITICAL: 1\n",
    "  HIGH: 4\n",
    "  MEDIUM: 1\n",
    "\n",
    "By Component:\n",
    "  data_loader: 3 errors\n",
    "  model_inference: 2 errors\n",
    "  api_server: 1 error\n",
    "\n",
    "Top Issues:\n",
    "  1. FileNotFoundError - 3 occurrences (data_loader)\n",
    "  2. CUDA_OUT_OF_MEMORY - 1 occurrence (model_inference)\n",
    "  3. InvalidInputShape - 1 occurrence (model_inference)\n",
    "\n",
    "⚠️ CRITICAL ISSUE: CUDA_OUT_OF_MEMORY at 02:16:45\n",
    "   Component: model_inference\n",
    "\n",
    "Recommendation: Check data_loader - 3 errors of same type\n",
    "\"\"\"\n",
    "\n",
    "# Your job: Generate this report programmatically\n",
    "# - Count by severity\n",
    "# - Count by component\n",
    "# - Find most common error types\n",
    "# - Identify critical errors\n",
    "# - Calculate time range"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
