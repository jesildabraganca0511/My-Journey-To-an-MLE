{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f49455",
   "metadata": {},
   "source": [
    "DAY 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb07f1",
   "metadata": {},
   "source": [
    "Exercise 1: Model Prediction Validator (20 min)\n",
    "Scenario: Your ML model returns predictions, but sometimes they're invalid. Build a validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d6ef3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n",
      "87.5\n",
      "87.5\n"
     ]
    }
   ],
   "source": [
    "# Model predictions with confidence scores\n",
    "predictions = [\n",
    "    {\"id\": 1, \"confidence\": 0.92, \"true_label\": 1},\n",
    "    {\"id\": 2, \"confidence\": 0.45, \"true_label\": 0},\n",
    "    {\"id\": 3, \"confidence\": 0.78, \"true_label\": 1},\n",
    "    {\"id\": 4, \"confidence\": 0.34, \"true_label\": 0},\n",
    "    {\"id\": 5, \"confidence\": 0.89, \"true_label\": 1},\n",
    "    {\"id\": 6, \"confidence\": 0.23, \"true_label\": 0},\n",
    "    {\"id\": 7, \"confidence\": 0.67, \"true_label\": 0},  # Should be misclassified at 0.5\n",
    "    {\"id\": 8, \"confidence\": 0.91, \"true_label\": 1},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# Test three different thresholds: 0.4, 0.5, 0.6\n",
    "# For each threshold:\n",
    "#   1. Convert confidence to binary prediction (>= threshold = 1, else 0)\n",
    "#   2. Calculate how many correct predictions\n",
    "#   3. Calculate accuracy\n",
    "# Find which threshold gives best accuracy\n",
    "#\n",
    "# Expected output:\n",
    "# Threshold 0.4: 7/8 correct (87.5% accuracy)\n",
    "# Threshold 0.5: X/8 correct (X% accuracy)\n",
    "# Threshold 0.6: X/8 correct (X% accuracy)\n",
    "# Best threshold: 0.X with X% accuracy\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "thresholds = [0.4, 0.5, 0.6]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    correct_count = 0\n",
    "    \n",
    "    for pred in predictions:\n",
    "        if pred[\"confidence\"]>= threshold:\n",
    "            temp_label=1\n",
    "        else:\n",
    "            temp_label=0\n",
    "\n",
    "        if pred[\"true_label\"]==temp_label:\n",
    "            correct_count+=1\n",
    "                \n",
    "        \n",
    "    acc=correct_count/len(predictions)\n",
    "    print (acc*100)  \n",
    "    \n",
    "    # Calculate and print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620887e",
   "metadata": {},
   "source": [
    "Exercise 2: Training Data Imbalance Detector (25 min)\n",
    "MLE Context: Imbalanced datasets hurt model performance. Detect and report class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf253a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "6\n",
      "0.25\n",
      "Highly imb\n"
     ]
    }
   ],
   "source": [
    "# Training dataset labels\n",
    "training_labels = [\n",
    "    1, 0, 1, 0, 0, 0, 1, 0, 0, 0,  # 3 positive, 7 negative\n",
    "    0, 0, 0, 1, 0, 0, 0, 0, 1, 0,  # 2 positive, 8 negative\n",
    "    0, 0, 0, 0, 0, 1, 0, 0, 0, 0,  # 1 positive, 9 negative\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Count class distribution (how many 0s, how many 1s)\n",
    "# 2. Calculate class imbalance ratio (minority_class / majority_class)\n",
    "# 3. Determine if dataset is imbalanced:\n",
    "#    - Balanced: ratio > 0.8\n",
    "#    - Slightly imbalanced: 0.5 <= ratio <= 0.8\n",
    "#    - Highly imbalanced: ratio < 0.5\n",
    "# 4. Calculate what percentage minority class represents\n",
    "#\n",
    "# Expected output:\n",
    "# Total samples: 30\n",
    "# Class 0: 24 samples (80.0%)\n",
    "# Class 1: 6 samples (20.0%)\n",
    "# Imbalance ratio: 0.25\n",
    "# Status: Highly imbalanced ⚠️\n",
    "# Recommendation: Consider resampling or class weights\n",
    "\n",
    "# YOUR CODE:\n",
    "class_0_count = 0\n",
    "class_1_count = 0\n",
    "\n",
    "for label in training_labels:\n",
    "    if label==1:\n",
    "        class_1_count+=1\n",
    "    else:\n",
    "        class_0_count+=1\n",
    "print(class_0_count)\n",
    "print(class_1_count)\n",
    "    \n",
    "if class_1_count>class_0_count:\n",
    "    ratio=class_0_count/class_1_count\n",
    "else:\n",
    "    ratio=class_1_count/class_0_count\n",
    "\n",
    "print(ratio)\n",
    "if ratio>0.8:\n",
    "    print(\"balanced\")\n",
    "elif 0.5 <= ratio <= 0.8:\n",
    "    print(\"Slightly imbalance\")\n",
    "\n",
    "else:\n",
    "    print(\"Highly imb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872cf64",
   "metadata": {},
   "source": [
    "Exercise 3: Feature Value Range Validator (30 min)\n",
    "MLE Context: Before training, validate that features are in expected ranges (data quality check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: ✓ Valid\n",
      "Sample 1: ✓ Valid\n",
      "Sample 2: ✓ Valid\n",
      "Sample 3: ✓ Valid\n",
      "Sample 4: ✓ Valid\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, dict found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m         valid_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: ✗ Invalid - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m         invalid_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, dict found"
     ]
    }
   ],
   "source": [
    "# Feature specifications (what's expected)\n",
    "feature_specs = {\n",
    "    \"age\": {\"min\": 0, \"max\": 120, \"type\": \"numeric\"},\n",
    "    \"income\": {\"min\": 0, \"max\": 1000000, \"type\": \"numeric\"},\n",
    "    \"credit_score\": {\"min\": 300, \"max\": 850, \"type\": \"numeric\"},\n",
    "    \"loan_amount\": {\"min\": 1000, \"max\": 500000, \"type\": \"numeric\"},\n",
    "}\n",
    "\n",
    "# Actual data samples\n",
    "samples = [\n",
    "    {\"age\": 25, \"income\": 50000, \"credit_score\": 720, \"loan_amount\": 15000},\n",
    "    {\"age\": -5, \"income\": 75000, \"credit_score\": 680, \"loan_amount\": 20000},      # Invalid age\n",
    "    {\"age\": 45, \"income\": 80000, \"credit_score\": 900, \"loan_amount\": 25000},      # Invalid credit_score\n",
    "    {\"age\": 35, \"income\": -10000, \"credit_score\": 700, \"loan_amount\": 30000},     # Invalid income\n",
    "    {\"age\": 150, \"income\": 60000, \"credit_score\": 640, \"loan_amount\": 18000},     # Invalid age\n",
    "    {\"age\": 30, \"income\": 70000, \"credit_score\": 750, \"loan_amount\": 600000},     # Invalid loan_amount\n",
    "    {\"age\": 28, \"income\": 55000, \"credit_score\": 710, \"loan_amount\": 22000},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. For each sample, validate ALL features against specs\n",
    "# 2. Track which samples are valid/invalid\n",
    "# 3. For invalid samples, list which features are out of range\n",
    "# 4. Calculate percentage of clean data\n",
    "#\n",
    "# Expected output:\n",
    "# Sample 0: ✓ Valid\n",
    "# Sample 1: ✗ Invalid - age: -5 (min: 0, max: 120)\n",
    "# Sample 2: ✗ Invalid - credit_score: 900 (min: 300, max: 850)\n",
    "# Sample 3: ✗ Invalid - income: -10000 (min: 0, max: 1000000)\n",
    "# Sample 4: ✗ Invalid - age: 150 (min: 0, max: 120)\n",
    "# Sample 5: ✗ Invalid - loan_amount: 600000 (min: 1000, max: 500000)\n",
    "# Sample 6: ✓ Valid\n",
    "#\n",
    "# Summary:\n",
    "# Total samples: 7\n",
    "# Valid: 2 (28.6%)\n",
    "# Invalid: 5 (71.4%)\n",
    "# Data quality: Poor - consider data cleaning\n",
    "\n",
    "# YOUR CODE:\n",
    "valid_count = 0\n",
    "invalid_count = 0\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "    is_valid = True\n",
    "    errors = []\n",
    "    \n",
    "    # Check each feature\n",
    "    for feature_name, value in sample.items():\n",
    "        spec = feature_specs[feature_name]\n",
    "        if (value<spec[\"min\"] or value> spec['max']):\n",
    "            is_valid=False\n",
    "            errors.append(f\"{feature_name}: {value} (min: {spec['min']}, max: {spec['max']})\")\n",
    "        \n",
    "       \n",
    "        pass\n",
    "    \n",
    "    if is_valid:\n",
    "        print(f\"Sample {idx}: ✓ Valid\")\n",
    "        valid_count += 1\n",
    "    else:\n",
    "        print(f\"Sample {idx}: ✗ Invalid - {', '.join(errors)}\")\n",
    "        invalid_count += 1\n",
    "\n",
    "# Print summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
