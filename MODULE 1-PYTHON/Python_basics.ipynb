{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eb07f1",
   "metadata": {},
   "source": [
    "Exercise 1: Data Quality Checker \n",
    "Real scenario: Your team receives daily CSV exports from a vendor. Before loading into the pipeline, you need to validate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ef3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_id': 'U001', 'age': 25, 'revenue': 150.5, 'country': 'US'}]\n",
      "[{'user_id': 'U002', 'age': -5, 'revenue': 200.0, 'country': 'UK'}, {'user_id': 'U003', 'age': 30, 'revenue': 'invalid', 'country': 'CA'}, {'user_id': '', 'age': 28, 'revenue': 175.25, 'country': 'US'}, {'user_id': 'U005', 'age': 150, 'revenue': 99.99, 'country': ''}]\n",
      "5\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# You receive this data structure (simulate it as variables):\n",
    "daily_records = [\n",
    "    {\"user_id\": \"U001\", \"age\": 25, \"revenue\": 150.50, \"country\": \"US\"},\n",
    "    {\"user_id\": \"U002\", \"age\": -5, \"revenue\": 200.00, \"country\": \"UK\"},  # Invalid age\n",
    "    {\"user_id\": \"U003\", \"age\": 30, \"revenue\": \"invalid\", \"country\": \"CA\"},  # Invalid revenue\n",
    "    {\"user_id\": \"\", \"age\": 28, \"revenue\": 175.25, \"country\": \"US\"},  # Missing user_id\n",
    "    {\"user_id\": \"U005\", \"age\": 150, \"revenue\": 99.99, \"country\": \"\"},  # Invalid age, missing country\n",
    "]\n",
    "\n",
    "valid_records=[]\n",
    "invalid_records=[]\n",
    "\n",
    "for i in daily_records:\n",
    "    if i['user_id'] !=\"\" and 0<=i['age']<=120 and (isinstance(i['revenue'],int) or isinstance(i['revenue'],float)) and i['country'] !=\"\" :\n",
    "        valid_records.append(i)\n",
    "    else:\n",
    "        invalid_records.append(i)\n",
    "        \n",
    "\n",
    "print(valid_records)\n",
    "print(invalid_records)\n",
    "\n",
    "\n",
    "print(len(daily_records))\n",
    "print(len(valid_records))\n",
    "print(len(invalid_records))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620887e",
   "metadata": {},
   "source": [
    "Exercise 2:This simulates a log file (normally you'd read from file, but start simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf253a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2026-01-26', '09:15:23', 'INFO', 'Model training started']\n",
      "['2026-01-26', '09:16:45', 'ERROR', 'Failed to load dataset: FileNotFoundError']\n",
      "['2026-01-26', '09:17:12', 'WARNING', 'Low memory: 85% used']\n",
      "['2026-01-26', '09:18:33', 'INFO', 'Epoch 1/10 completed']\n",
      "['2026-01-26', '09:19:44', 'ERROR', 'CUDA out of memory']\n",
      "['2026-01-26', '09:20:15', 'ERROR', 'Failed to load dataset: FileNotFoundError']\n",
      "['2026-01-26', '09:21:05', 'INFO', 'Model saved successfully']\n",
      "['2026-01-26', '09:22:18', 'WARNING', 'Validation accuracy below threshold']\n",
      "['09:15:23', '09:16:45', '09:17:12', '09:18:33', '09:19:44', '09:20:15', '09:21:05', '09:22:18']\n",
      "['INFO', 'ERROR', 'WARNING', 'INFO', 'ERROR', 'ERROR', 'INFO', 'WARNING']\n",
      "['Model training started', 'Failed to load dataset: FileNotFoundError', 'Low memory: 85% used', 'Epoch 1/10 completed', 'CUDA out of memory', 'Failed to load dataset: FileNotFoundError', 'Model saved successfully', 'Validation accuracy below threshold']\n"
     ]
    }
   ],
   "source": [
    "log_entries = [\n",
    "    \"2026-01-26 09:15:23 INFO Model training started\",\n",
    "    \"2026-01-26 09:16:45 ERROR Failed to load dataset: FileNotFoundError\",\n",
    "    \"2026-01-26 09:17:12 WARNING Low memory: 85% used\",\n",
    "    \"2026-01-26 09:18:33 INFO Epoch 1/10 completed\",\n",
    "    \"2026-01-26 09:19:44 ERROR CUDA out of memory\",\n",
    "    \"2026-01-26 09:20:15 ERROR Failed to load dataset: FileNotFoundError\",  # Duplicate\n",
    "    \"2026-01-26 09:21:05 INFO Model saved successfully\",\n",
    "    \"2026-01-26 09:22:18 WARNING Validation accuracy below threshold\",\n",
    "]\n",
    "\n",
    "#q1\n",
    "times=[]\n",
    "log_level=[]\n",
    "msg=[]\n",
    "for i in log_entries:\n",
    "    s=i.split(\" \",3)\n",
    "    print(s)\n",
    "    times.append(s[1])\n",
    "    log_level.append(s[2])\n",
    "    msg.append(s[-1])\n",
    "print(times) \n",
    "print(log_level)\n",
    "print(msg)\n",
    "\n",
    "#q2\n",
    "logs_per_level = {}\n",
    "\n",
    "for i in log_level:\n",
    "    if i not in logs_per_level:\n",
    "        logs_per_level[i]=1\n",
    "    else:\n",
    "        logs_per_level[i]+=1\n",
    "\n",
    "logs_per_level = {}\n",
    "\n",
    "\n",
    "\n",
    "unique_errors = set()\n",
    "\n",
    "for i in range(len(log_level)):\n",
    "    if log_level[i] == \"ERROR\":\n",
    "        unique_errors.add(msg[i])\n",
    "\n",
    "\n",
    "#q3\n",
    "first_error_index = log_level.index(\"ERROR\")\n",
    "first_error_time = times[first_error_index]\n",
    "\n",
    "#q4\n",
    "\n",
    "error_counts = {}\n",
    "\n",
    "for i in range(len(log_level)):\n",
    "    if log_level[i] == \"ERROR\":\n",
    "        if msg[i] not in error_counts:\n",
    "            error_counts[msg[i]] = 1\n",
    "        else:\n",
    "            error_counts[msg[i]] += 1\n",
    "\n",
    "most_common_error = max(error_counts, key=error_counts.get)\n",
    "most_common_error_count = error_counts[most_common_error]\n",
    "\n",
    "\n",
    "\n",
    "# 3. Find:\n",
    "#    - Time of first ERROR\n",
    "#    - Most common error message\n",
    "#\n",
    "# 4. Print report:\n",
    "#    \"\"\"\n",
    "#    === Log Summary ===\n",
    "#    Total entries: 8\n",
    "#    INFO: 3\n",
    "#    WARNING: 2\n",
    "#    ERROR: 3\n",
    "#    \n",
    "#    First error at: 09:16:45\n",
    "#    Unique errors: 2\n",
    "#    Most common error: Failed to load dataset: FileNotFoundError (appeared 2 times)\n",
    "#    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872cf64",
   "metadata": {},
   "source": [
    "EXERCISE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f3f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Config invalid:\n"
     ]
    }
   ],
   "source": [
    "# This simulates a config file (later you'll read from JSON/YAML)\n",
    "training_config1 = {\n",
    "    \"model_name\": \"resnet50\",\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 100,\n",
    "    \"gpu_id\": 0,\n",
    "    \"data_path\": \"/data/imagenet\",\n",
    "    \"save_checkpoints\": True,\n",
    "}\n",
    "\n",
    "# Validation rules (your manager gives you these):\n",
    "VALID_MODELS = [\"resnet50\", \"vgg16\", \"efficientnet\"]\n",
    "MIN_BATCH_SIZE = 1\n",
    "MAX_BATCH_SIZE = 512\n",
    "MIN_LR = 0.00001\n",
    "MAX_LR = 1.0\n",
    "MIN_EPOCHS = 1\n",
    "MAX_EPOCHS = 1000\n",
    "\n",
    "\n",
    "# 2. If ALL valid: print \"✓ Config valid. Safe to start training.\"\n",
    "# 3. If ANY invalid: print \"✗ Config invalid:\" and list ALL issues\n",
    "#    Example: \"✗ Config invalid:\n",
    "#             - batch_size 1024 exceeds maximum 512\n",
    "#             - learning_rate 5.0 exceeds maximum 1.0\"\n",
    "#\n",
    "# 3. Test with INVALID config:\n",
    "training_config = {\n",
    "    \"model_name\": \"bert\",  # Not in valid models\n",
    "    \"batch_size\": 1024,    # Too large\n",
    "    \"learning_rate\": 5.0,  # Too large\n",
    "    \"epochs\": -10,         # Negative\n",
    "    \"gpu_id\": -1,          # Negative\n",
    "    \"data_path\": \"\",       # Empty\n",
    "    \"save_checkpoints\": \"yes\",  # Wrong type\n",
    "}\n",
    "\n",
    "# Your job:\n",
    "# 1. Check:\n",
    "#    - model_name is in VALID_MODELS\n",
    "#    - batch_size is between MIN and MAX\n",
    "#    - learning_rate is between MIN and MAX\n",
    "#    - epochs is between MIN and MAX\n",
    "#    - gpu_id is 0 or positi\n",
    "#    - data_path is not empty string\n",
    "#    - save_checkpoints is True or False (boolean)\n",
    "if training_config['model_name'] in VALID_MODELS and MIN_BATCH_SIZE<=training_config[\"batch_size\"]<=MAX_BATCH_SIZE and MIN_LR<=training_config[\"learning_rate\"]<=MAX_LR and MIN_EPOCHS<=training_config[\"epochs\"]<=MAX_EPOCHS and training_config['gpu_id'] >=0 and training_config['data_path']!= \"\" and (training_config['save_checkpoints'] ==True or training_config['save_checkpoints'] ==False):\n",
    "    print('✓ Config valid. Safe to start training.')\n",
    "else:\n",
    "    print('✗ Config invalid:')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data from database (simulate as list of dicts)\n",
    "users = [\n",
    "    {\"user_id\": \"U001\", \"signup_date\": \"2025-01-15\", \"last_login\": \"2026-01-25\", \n",
    "     \"purchases\": 5, \"total_spent\": 499.99, \"email_domain\": \"gmail.com\"},\n",
    "    \n",
    "    {\"user_id\": \"U002\", \"signup_date\": \"2024-06-20\", \"last_login\": \"2026-01-20\",\n",
    "     \"purchases\": 0, \"total_spent\": 0, \"email_domain\": \"yahoo.com\"},\n",
    "    \n",
    "    {\"user_id\": \"U003\", \"signup_date\": \"2025-11-01\", \"last_login\": \"2026-01-26\",\n",
    "     \"purchases\": 12, \"total_spent\": 1250.00, \"email_domain\": \"company.com\"},\n",
    "    \n",
    "    {\"user_id\": \"U004\", \"signup_date\": \"2023-03-10\", \"last_login\": \"2025-12-15\",\n",
    "     \"purchases\": 3, \"total_spent\": 150.00, \"email_domain\": \"gmail.com\"},\n",
    "]\n",
    "import datetime\n",
    "# Your job - calculate these features for EACH user:\n",
    "# 1. days_since_signup: days between signup_date and today (2026-01-26)\n",
    "# 2. days_since_last_login: days between last_login and today\n",
    "# 3. average_purchase_value: total_spent / purchases (handle division by zero!)\n",
    "# 4. is_active: True if last_login was within 7 days, False otherwise\n",
    "# 5. is_high_value: True if total_spent > 500, False otherwise\n",
    "# 6. is_enterprise_email: True if email_domain is NOT gmail/yahoo/hotmail\n",
    "\n",
    "# Create NEW list with enriched data:\n",
    "enriched_users = [\n",
    "    {\n",
    "        \"user_id\": \"U001\",\n",
    "        \"days_since_signup\": 376,  # Calculate this\n",
    "        \"days_since_last_login\": 1,\n",
    "        \"average_purchase_value\": 99.99,\n",
    "        \"is_active\": True,\n",
    "        \"is_high_value\": False,\n",
    "        \"is_enterprise_email\": False,\n",
    "    },\n",
    "    # ... for all users\n",
    "]\n",
    "\n",
    "# Print summary stats:\n",
    "# Total users: 4\n",
    "# Active users: 2\n",
    "# High-value users: 1\n",
    "# Enterprise emails: 1\n",
    "# Average purchase value (all users): $X.XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate errors collected from monitoring system\n",
    "errors = [\n",
    "    {\"timestamp\": \"2026-01-26 02:15:33\", \"component\": \"data_loader\", \n",
    "     \"error_type\": \"FileNotFoundError\", \"severity\": \"HIGH\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 02:16:45\", \"component\": \"model_inference\", \n",
    "     \"error_type\": \"CUDA_OUT_OF_MEMORY\", \"severity\": \"CRITICAL\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 02:17:12\", \"component\": \"data_loader\", \n",
    "     \"error_type\": \"FileNotFoundError\", \"severity\": \"HIGH\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 03:22:05\", \"component\": \"api_server\", \n",
    "     \"error_type\": \"TimeoutError\", \"severity\": \"MEDIUM\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 03:45:18\", \"component\": \"model_inference\", \n",
    "     \"error_type\": \"InvalidInputShape\", \"severity\": \"HIGH\"},\n",
    "    \n",
    "    {\"timestamp\": \"2026-01-26 04:10:33\", \"component\": \"data_loader\", \n",
    "     \"error_type\": \"FileNotFoundError\", \"severity\": \"HIGH\"},\n",
    "]\n",
    "\n",
    "# Generate report:\n",
    "\"\"\"\n",
    "=== OVERNIGHT ERROR REPORT ===\n",
    "Time range: 02:15:33 - 04:10:33\n",
    "Total errors: 6\n",
    "\n",
    "By Severity:\n",
    "  CRITICAL: 1\n",
    "  HIGH: 4\n",
    "  MEDIUM: 1\n",
    "\n",
    "By Component:\n",
    "  data_loader: 3 errors\n",
    "  model_inference: 2 errors\n",
    "  api_server: 1 error\n",
    "\n",
    "Top Issues:\n",
    "  1. FileNotFoundError - 3 occurrences (data_loader)\n",
    "  2. CUDA_OUT_OF_MEMORY - 1 occurrence (model_inference)\n",
    "  3. InvalidInputShape - 1 occurrence (model_inference)\n",
    "\n",
    "⚠️ CRITICAL ISSUE: CUDA_OUT_OF_MEMORY at 02:16:45\n",
    "   Component: model_inference\n",
    "\n",
    "Recommendation: Check data_loader - 3 errors of same type\n",
    "\"\"\"\n",
    "\n",
    "# Your job: Generate this report programmatically\n",
    "# - Count by severity\n",
    "# - Count by component\n",
    "# - Find most common error types\n",
    "# - Identify critical errors\n",
    "# - Calculate time range"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
