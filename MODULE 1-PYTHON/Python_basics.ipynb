{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f49455",
   "metadata": {},
   "source": [
    "DAY 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb07f1",
   "metadata": {},
   "source": [
    "Exercise 1: Model Prediction Validator (20 min)\n",
    "Scenario: Your ML model returns predictions, but sometimes they're invalid. Build a validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d6ef3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n",
      "87.5\n",
      "87.5\n"
     ]
    }
   ],
   "source": [
    "# Model predictions with confidence scores\n",
    "predictions = [\n",
    "    {\"id\": 1, \"confidence\": 0.92, \"true_label\": 1},\n",
    "    {\"id\": 2, \"confidence\": 0.45, \"true_label\": 0},\n",
    "    {\"id\": 3, \"confidence\": 0.78, \"true_label\": 1},\n",
    "    {\"id\": 4, \"confidence\": 0.34, \"true_label\": 0},\n",
    "    {\"id\": 5, \"confidence\": 0.89, \"true_label\": 1},\n",
    "    {\"id\": 6, \"confidence\": 0.23, \"true_label\": 0},\n",
    "    {\"id\": 7, \"confidence\": 0.67, \"true_label\": 0},  # Should be misclassified at 0.5\n",
    "    {\"id\": 8, \"confidence\": 0.91, \"true_label\": 1},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# Test three different thresholds: 0.4, 0.5, 0.6\n",
    "# For each threshold:\n",
    "#   1. Convert confidence to binary prediction (>= threshold = 1, else 0)\n",
    "#   2. Calculate how many correct predictions\n",
    "#   3. Calculate accuracy\n",
    "# Find which threshold gives best accuracy\n",
    "#\n",
    "# Expected output:\n",
    "# Threshold 0.4: 7/8 correct (87.5% accuracy)\n",
    "# Threshold 0.5: X/8 correct (X% accuracy)\n",
    "# Threshold 0.6: X/8 correct (X% accuracy)\n",
    "# Best threshold: 0.X with X% accuracy\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "thresholds = [0.4, 0.5, 0.6]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    correct_count = 0\n",
    "    \n",
    "    for pred in predictions:\n",
    "        if pred[\"confidence\"]>= threshold:\n",
    "            temp_label=1\n",
    "        else:\n",
    "            temp_label=0\n",
    "\n",
    "        if pred[\"true_label\"]==temp_label:\n",
    "            correct_count+=1\n",
    "                \n",
    "        \n",
    "    acc=correct_count/len(predictions)\n",
    "    print (acc*100)  \n",
    "    \n",
    "    # Calculate and print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620887e",
   "metadata": {},
   "source": [
    "Exercise 2: Training Data Imbalance Detector (25 min)\n",
    "MLE Context: Imbalanced datasets hurt model performance. Detect and report class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf253a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "6\n",
      "0.25\n",
      "Highly imb\n"
     ]
    }
   ],
   "source": [
    "# Training dataset labels\n",
    "training_labels = [\n",
    "    1, 0, 1, 0, 0, 0, 1, 0, 0, 0,  # 3 positive, 7 negative\n",
    "    0, 0, 0, 1, 0, 0, 0, 0, 1, 0,  # 2 positive, 8 negative\n",
    "    0, 0, 0, 0, 0, 1, 0, 0, 0, 0,  # 1 positive, 9 negative\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Count class distribution (how many 0s, how many 1s)\n",
    "# 2. Calculate class imbalance ratio (minority_class / majority_class)\n",
    "# 3. Determine if dataset is imbalanced:\n",
    "#    - Balanced: ratio > 0.8\n",
    "#    - Slightly imbalanced: 0.5 <= ratio <= 0.8\n",
    "#    - Highly imbalanced: ratio < 0.5\n",
    "# 4. Calculate what percentage minority class represents\n",
    "#\n",
    "# Expected output:\n",
    "# Total samples: 30\n",
    "# Class 0: 24 samples (80.0%)\n",
    "# Class 1: 6 samples (20.0%)\n",
    "# Imbalance ratio: 0.25\n",
    "# Status: Highly imbalanced ‚ö†Ô∏è\n",
    "# Recommendation: Consider resampling or class weights\n",
    "\n",
    "# YOUR CODE:\n",
    "class_0_count = 0\n",
    "class_1_count = 0\n",
    "\n",
    "for label in training_labels:\n",
    "    if label==1:\n",
    "        class_1_count+=1\n",
    "    else:\n",
    "        class_0_count+=1\n",
    "print(class_0_count)\n",
    "print(class_1_count)\n",
    "    \n",
    "if class_1_count>class_0_count:\n",
    "    ratio=class_0_count/class_1_count\n",
    "else:\n",
    "    ratio=class_1_count/class_0_count\n",
    "\n",
    "print(ratio)\n",
    "if ratio>0.8:\n",
    "    print(\"balanced\")\n",
    "elif 0.5 <= ratio <= 0.8:\n",
    "    print(\"Slightly imbalance\")\n",
    "\n",
    "else:\n",
    "    print(\"Highly imb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872cf64",
   "metadata": {},
   "source": [
    "Exercise 3: Feature Value Range Validator (30 min)\n",
    "MLE Context: Before training, validate that features are in expected ranges (data quality check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: ‚úì Valid\n",
      "Sample 1: ‚úó Invalid - age: -5 (min: 0, max: 120)\n",
      "Sample 2: ‚úó Invalid - credit_score: 900 (min: 300, max: 850)\n",
      "Sample 3: ‚úó Invalid - income: -10000 (min: 0, max: 1000000)\n",
      "Sample 4: ‚úó Invalid - age: 150 (min: 0, max: 120)\n",
      "Sample 5: ‚úó Invalid - loan_amount: 600000 (min: 1000, max: 500000)\n",
      "Sample 6: ‚úì Valid\n"
     ]
    }
   ],
   "source": [
    "# Feature specifications (what's expected)\n",
    "feature_specs = {\n",
    "    \"age\": {\"min\": 0, \"max\": 120, \"type\": \"numeric\"},\n",
    "    \"income\": {\"min\": 0, \"max\": 1000000, \"type\": \"numeric\"},\n",
    "    \"credit_score\": {\"min\": 300, \"max\": 850, \"type\": \"numeric\"},\n",
    "    \"loan_amount\": {\"min\": 1000, \"max\": 500000, \"type\": \"numeric\"},\n",
    "}\n",
    "\n",
    "# Actual data samples\n",
    "samples = [\n",
    "    {\"age\": 25, \"income\": 50000, \"credit_score\": 720, \"loan_amount\": 15000},\n",
    "    {\"age\": -5, \"income\": 75000, \"credit_score\": 680, \"loan_amount\": 20000},      # Invalid age\n",
    "    {\"age\": 45, \"income\": 80000, \"credit_score\": 900, \"loan_amount\": 25000},      # Invalid credit_score\n",
    "    {\"age\": 35, \"income\": -10000, \"credit_score\": 700, \"loan_amount\": 30000},     # Invalid income\n",
    "    {\"age\": 150, \"income\": 60000, \"credit_score\": 640, \"loan_amount\": 18000},     # Invalid age\n",
    "    {\"age\": 30, \"income\": 70000, \"credit_score\": 750, \"loan_amount\": 600000},     # Invalid loan_amount\n",
    "    {\"age\": 28, \"income\": 55000, \"credit_score\": 710, \"loan_amount\": 22000},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. For each sample, validate ALL features against specs\n",
    "# 2. Track which samples are valid/invalid\n",
    "# 3. For invalid samples, list which features are out of range\n",
    "# 4. Calculate percentage of clean data\n",
    "#\n",
    "# Expected output:\n",
    "# Sample 0: ‚úì Valid\n",
    "# Sample 1: ‚úó Invalid - age: -5 (min: 0, max: 120)\n",
    "# Sample 2: ‚úó Invalid - credit_score: 900 (min: 300, max: 850)\n",
    "# Sample 3: ‚úó Invalid - income: -10000 (min: 0, max: 1000000)\n",
    "# Sample 4: ‚úó Invalid - age: 150 (min: 0, max: 120)\n",
    "# Sample 5: ‚úó Invalid - loan_amount: 600000 (min: 1000, max: 500000)\n",
    "# Sample 6: ‚úì Valid\n",
    "#\n",
    "# Summary:\n",
    "# Total samples: 7\n",
    "# Valid: 2 (28.6%)\n",
    "# Invalid: 5 (71.4%)\n",
    "# Data quality: Poor - consider data cleaning\n",
    "\n",
    "# YOUR CODE:\n",
    "valid_count = 0\n",
    "invalid_count = 0\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "    is_valid = True\n",
    "    errors = []\n",
    "    \n",
    "    # Check each feature\n",
    "    for feature_name, value in sample.items():\n",
    "        spec = feature_specs[feature_name]\n",
    "        if (value<spec[\"min\"] or value> spec['max']):\n",
    "            is_valid=False\n",
    "            errors.append(f\"{feature_name}: {value} (min: {spec['min']}, max: {spec['max']})\")\n",
    "        \n",
    "       \n",
    "        \n",
    "    \n",
    "    if is_valid:\n",
    "        print(f\"Sample {idx}: ‚úì Valid\")\n",
    "        valid_count += 1\n",
    "    else:\n",
    "        print(f\"Sample {idx}: ‚úó Invalid - {', '.join(errors)}\")\n",
    "        invalid_count += 1\n",
    "\n",
    "# Print summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef53157",
   "metadata": {},
   "source": [
    "DAY 2: Loops & Iteration (75 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186986d",
   "metadata": {},
   "source": [
    "Exercise 1: Mini-Batch Gradient Descent Simulator (20 min)\n",
    "MLE Context: Training neural networks with mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dd46c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1/3 ===\n",
      "Processing batch 1/49: samples 0-31 (32 samples)\n",
      "Processing batch 2/49: samples 32-63 (32 samples)\n",
      "Processing batch 3/49: samples 64-95 (32 samples)\n",
      "Processing batch 4/49: samples 96-127 (32 samples)\n",
      "Processing batch 5/49: samples 128-159 (32 samples)\n",
      "Processing batch 6/49: samples 160-191 (32 samples)\n",
      "Processing batch 7/49: samples 192-223 (32 samples)\n",
      "Processing batch 8/49: samples 224-255 (32 samples)\n",
      "Processing batch 9/49: samples 256-287 (32 samples)\n",
      "Processing batch 10/49: samples 288-319 (32 samples)\n",
      "Processing batch 11/49: samples 320-351 (32 samples)\n",
      "Processing batch 12/49: samples 352-383 (32 samples)\n",
      "Processing batch 13/49: samples 384-415 (32 samples)\n",
      "Processing batch 14/49: samples 416-447 (32 samples)\n",
      "Processing batch 15/49: samples 448-479 (32 samples)\n",
      "Processing batch 16/49: samples 480-511 (32 samples)\n",
      "Processing batch 17/49: samples 512-543 (32 samples)\n",
      "Processing batch 18/49: samples 544-575 (32 samples)\n",
      "Processing batch 19/49: samples 576-607 (32 samples)\n",
      "Processing batch 20/49: samples 608-639 (32 samples)\n",
      "Processing batch 21/49: samples 640-671 (32 samples)\n",
      "Processing batch 22/49: samples 672-703 (32 samples)\n",
      "Processing batch 23/49: samples 704-735 (32 samples)\n",
      "Processing batch 24/49: samples 736-767 (32 samples)\n",
      "Processing batch 25/49: samples 768-799 (32 samples)\n",
      "Processing batch 26/49: samples 800-831 (32 samples)\n",
      "Processing batch 27/49: samples 832-863 (32 samples)\n",
      "Processing batch 28/49: samples 864-895 (32 samples)\n",
      "Processing batch 29/49: samples 896-927 (32 samples)\n",
      "Processing batch 30/49: samples 928-959 (32 samples)\n",
      "Processing batch 31/49: samples 960-991 (32 samples)\n",
      "Processing batch 32/49: samples 992-1023 (32 samples)\n",
      "Processing batch 33/49: samples 1024-1055 (32 samples)\n",
      "Processing batch 34/49: samples 1056-1087 (32 samples)\n",
      "Processing batch 35/49: samples 1088-1119 (32 samples)\n",
      "Processing batch 36/49: samples 1120-1151 (32 samples)\n",
      "Processing batch 37/49: samples 1152-1183 (32 samples)\n",
      "Processing batch 38/49: samples 1184-1215 (32 samples)\n",
      "Processing batch 39/49: samples 1216-1247 (32 samples)\n",
      "Processing batch 40/49: samples 1248-1279 (32 samples)\n",
      "Processing batch 41/49: samples 1280-1311 (32 samples)\n",
      "Processing batch 42/49: samples 1312-1343 (32 samples)\n",
      "Processing batch 43/49: samples 1344-1375 (32 samples)\n",
      "Processing batch 44/49: samples 1376-1407 (32 samples)\n",
      "Processing batch 45/49: samples 1408-1439 (32 samples)\n",
      "Processing batch 46/49: samples 1440-1471 (32 samples)\n",
      "Processing batch 47/49: samples 1472-1503 (32 samples)\n",
      "Processing batch 48/49: samples 1504-1535 (32 samples)\n",
      "Processing batch 49/49: samples 1536-1546 (11 samples)\n",
      "=== Epoch 2/3 ===\n",
      "Processing batch 1/49: samples 0-31 (32 samples)\n",
      "Processing batch 2/49: samples 32-63 (32 samples)\n",
      "Processing batch 3/49: samples 64-95 (32 samples)\n",
      "Processing batch 4/49: samples 96-127 (32 samples)\n",
      "Processing batch 5/49: samples 128-159 (32 samples)\n",
      "Processing batch 6/49: samples 160-191 (32 samples)\n",
      "Processing batch 7/49: samples 192-223 (32 samples)\n",
      "Processing batch 8/49: samples 224-255 (32 samples)\n",
      "Processing batch 9/49: samples 256-287 (32 samples)\n",
      "Processing batch 10/49: samples 288-319 (32 samples)\n",
      "Processing batch 11/49: samples 320-351 (32 samples)\n",
      "Processing batch 12/49: samples 352-383 (32 samples)\n",
      "Processing batch 13/49: samples 384-415 (32 samples)\n",
      "Processing batch 14/49: samples 416-447 (32 samples)\n",
      "Processing batch 15/49: samples 448-479 (32 samples)\n",
      "Processing batch 16/49: samples 480-511 (32 samples)\n",
      "Processing batch 17/49: samples 512-543 (32 samples)\n",
      "Processing batch 18/49: samples 544-575 (32 samples)\n",
      "Processing batch 19/49: samples 576-607 (32 samples)\n",
      "Processing batch 20/49: samples 608-639 (32 samples)\n",
      "Processing batch 21/49: samples 640-671 (32 samples)\n",
      "Processing batch 22/49: samples 672-703 (32 samples)\n",
      "Processing batch 23/49: samples 704-735 (32 samples)\n",
      "Processing batch 24/49: samples 736-767 (32 samples)\n",
      "Processing batch 25/49: samples 768-799 (32 samples)\n",
      "Processing batch 26/49: samples 800-831 (32 samples)\n",
      "Processing batch 27/49: samples 832-863 (32 samples)\n",
      "Processing batch 28/49: samples 864-895 (32 samples)\n",
      "Processing batch 29/49: samples 896-927 (32 samples)\n",
      "Processing batch 30/49: samples 928-959 (32 samples)\n",
      "Processing batch 31/49: samples 960-991 (32 samples)\n",
      "Processing batch 32/49: samples 992-1023 (32 samples)\n",
      "Processing batch 33/49: samples 1024-1055 (32 samples)\n",
      "Processing batch 34/49: samples 1056-1087 (32 samples)\n",
      "Processing batch 35/49: samples 1088-1119 (32 samples)\n",
      "Processing batch 36/49: samples 1120-1151 (32 samples)\n",
      "Processing batch 37/49: samples 1152-1183 (32 samples)\n",
      "Processing batch 38/49: samples 1184-1215 (32 samples)\n",
      "Processing batch 39/49: samples 1216-1247 (32 samples)\n",
      "Processing batch 40/49: samples 1248-1279 (32 samples)\n",
      "Processing batch 41/49: samples 1280-1311 (32 samples)\n",
      "Processing batch 42/49: samples 1312-1343 (32 samples)\n",
      "Processing batch 43/49: samples 1344-1375 (32 samples)\n",
      "Processing batch 44/49: samples 1376-1407 (32 samples)\n",
      "Processing batch 45/49: samples 1408-1439 (32 samples)\n",
      "Processing batch 46/49: samples 1440-1471 (32 samples)\n",
      "Processing batch 47/49: samples 1472-1503 (32 samples)\n",
      "Processing batch 48/49: samples 1504-1535 (32 samples)\n",
      "Processing batch 49/49: samples 1536-1546 (11 samples)\n",
      "=== Epoch 3/3 ===\n",
      "Processing batch 1/49: samples 0-31 (32 samples)\n",
      "Processing batch 2/49: samples 32-63 (32 samples)\n",
      "Processing batch 3/49: samples 64-95 (32 samples)\n",
      "Processing batch 4/49: samples 96-127 (32 samples)\n",
      "Processing batch 5/49: samples 128-159 (32 samples)\n",
      "Processing batch 6/49: samples 160-191 (32 samples)\n",
      "Processing batch 7/49: samples 192-223 (32 samples)\n",
      "Processing batch 8/49: samples 224-255 (32 samples)\n",
      "Processing batch 9/49: samples 256-287 (32 samples)\n",
      "Processing batch 10/49: samples 288-319 (32 samples)\n",
      "Processing batch 11/49: samples 320-351 (32 samples)\n",
      "Processing batch 12/49: samples 352-383 (32 samples)\n",
      "Processing batch 13/49: samples 384-415 (32 samples)\n",
      "Processing batch 14/49: samples 416-447 (32 samples)\n",
      "Processing batch 15/49: samples 448-479 (32 samples)\n",
      "Processing batch 16/49: samples 480-511 (32 samples)\n",
      "Processing batch 17/49: samples 512-543 (32 samples)\n",
      "Processing batch 18/49: samples 544-575 (32 samples)\n",
      "Processing batch 19/49: samples 576-607 (32 samples)\n",
      "Processing batch 20/49: samples 608-639 (32 samples)\n",
      "Processing batch 21/49: samples 640-671 (32 samples)\n",
      "Processing batch 22/49: samples 672-703 (32 samples)\n",
      "Processing batch 23/49: samples 704-735 (32 samples)\n",
      "Processing batch 24/49: samples 736-767 (32 samples)\n",
      "Processing batch 25/49: samples 768-799 (32 samples)\n",
      "Processing batch 26/49: samples 800-831 (32 samples)\n",
      "Processing batch 27/49: samples 832-863 (32 samples)\n",
      "Processing batch 28/49: samples 864-895 (32 samples)\n",
      "Processing batch 29/49: samples 896-927 (32 samples)\n",
      "Processing batch 30/49: samples 928-959 (32 samples)\n",
      "Processing batch 31/49: samples 960-991 (32 samples)\n",
      "Processing batch 32/49: samples 992-1023 (32 samples)\n",
      "Processing batch 33/49: samples 1024-1055 (32 samples)\n",
      "Processing batch 34/49: samples 1056-1087 (32 samples)\n",
      "Processing batch 35/49: samples 1088-1119 (32 samples)\n",
      "Processing batch 36/49: samples 1120-1151 (32 samples)\n",
      "Processing batch 37/49: samples 1152-1183 (32 samples)\n",
      "Processing batch 38/49: samples 1184-1215 (32 samples)\n",
      "Processing batch 39/49: samples 1216-1247 (32 samples)\n",
      "Processing batch 40/49: samples 1248-1279 (32 samples)\n",
      "Processing batch 41/49: samples 1280-1311 (32 samples)\n",
      "Processing batch 42/49: samples 1312-1343 (32 samples)\n",
      "Processing batch 43/49: samples 1344-1375 (32 samples)\n",
      "Processing batch 44/49: samples 1376-1407 (32 samples)\n",
      "Processing batch 45/49: samples 1408-1439 (32 samples)\n",
      "Processing batch 46/49: samples 1440-1471 (32 samples)\n",
      "Processing batch 47/49: samples 1472-1503 (32 samples)\n",
      "Processing batch 48/49: samples 1504-1535 (32 samples)\n",
      "Processing batch 49/49: samples 1536-1546 (11 samples)\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "total_samples = 1547  # Your dataset size\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE:\n",
    "import math\n",
    "\n",
    "total_batches= math.ceil(total_samples/batch_size)\n",
    "\n",
    "for i in range(1,epochs+1):\n",
    "    \n",
    "    print(f\"=== Epoch {i}/{epochs} ===\")\n",
    "    for batch_num in range(1,total_batches+1):\n",
    "        start= (batch_num-1)*32\n",
    "        end_idx = min(start + batch_size - 1, total_samples - 1)\n",
    "        samples_in_batch = end_idx - start + 1\n",
    "        print(f\"Processing batch {batch_num}/49: samples {start}-{end_idx} ({samples_in_batch} samples)\")\n",
    "\n",
    "# Print final summary\n",
    "\n",
    "# YOUR TASK:\n",
    "# Simulate training loop:\n",
    "# 1. For each epoch:\n",
    "#    - Calculate how many batches per epoch\n",
    "#    - Calculate samples in last (partial) batch\n",
    "#    - Print batch processing info\n",
    "# 2. Track total batches processed across all epochs\n",
    "# 3. Track total gradient updates (one per batch)\n",
    "#\n",
    "# Expected output:\n",
    "# === Epoch 1/3 ===\n",
    "# Processing batch 1/49: samples 0-31 (32 samples)\n",
    "# Processing batch 2/49: samples 32-63 (32 samples)\n",
    "# ...\n",
    "# Processing batch 49/49: samples 1536-1546 (11 samples) [partial batch]\n",
    "# Epoch 1 complete: 49 batches, 1547 samples\n",
    "#\n",
    "# === Epoch 2/3 ===\n",
    "# ...\n",
    "#\n",
    "# === Training Complete ===\n",
    "# Total epochs: 3\n",
    "# Total batches processed: 147\n",
    "# Total gradient updates: 147\n",
    "# Samples seen: 4641 (with repetition across epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d43afb",
   "metadata": {},
   "source": [
    "Exercise 2: Early Stopping with Patience (25 min)\n",
    "MLE Context: Stop training when validation loss stops improving (avoid overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ff2de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: val_loss=0.86 (new best ‚¨áÔ∏è)\n",
      "Epoch2 : val_loss =0.73 (improved by 0.122\n",
      "Epoch3 : val_loss =0.65 (improved by 0.083\n",
      "Epoch4 : val_loss =0.60 (improved by 0.049\n",
      "Epoch5 : val_loss =0.58 (improved by 0.024\n",
      "Epoch6 : val_loss =0.56 (improved by 0.013\n",
      "Epoch 7: val_loss=0.5590 (improved by 0.0060 ‚û°Ô∏è patience 1/3)\n",
      "Epoch 8: val_loss=0.5560 (improved by 0.0090 ‚û°Ô∏è patience 2/3)\n",
      "Epoch 9: val_loss=0.5550 (improved by 0.0100 ‚û°Ô∏è patience 3/3)\n",
      "\n",
      "üõë Early stopping triggered at epoch 9\n"
     ]
    }
   ],
   "source": [
    "# Validation losses per epoch (simulated)\n",
    "val_losses = [\n",
    "    0.856, 0.734, 0.651, 0.602, 0.578,  # Improving\n",
    "    0.565, 0.559, 0.556, 0.555, 0.554,  # Small improvements\n",
    "    0.5535, 0.5534, 0.5533, 0.5532,     # Tiny improvements (should trigger early stop)\n",
    "]\n",
    "\n",
    "# Early stopping config\n",
    "patience = 3  # Stop if no improvement for 3 epochs\n",
    "min_delta = 0.01  # Minimum improvement to count as \"better\"\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Track best validation loss seen so far\n",
    "# 2. Track epochs since last improvement\n",
    "# 3. For each epoch:\n",
    "#    - Check if current loss is better than best by at least min_delta\n",
    "#    - If yes: update best, reset patience counter\n",
    "#    - If no: increment patience counter\n",
    "# 4. Stop training if patience counter reaches limit\n",
    "# 5. Report at which epoch you would have stopped\n",
    "\n",
    "\n",
    "# YOUR CODE:\n",
    "best_loss =  float('inf')\n",
    "epochs_no_improvement = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch, loss in enumerate(val_losses, start=1):\n",
    "    \n",
    "    improvement = best_loss- loss\n",
    "    if improvement>= min_delta:\n",
    "        best_loss= loss\n",
    "        best_epoch=epoch\n",
    "        if epoch==1:\n",
    "            print(f\"Epoch {epoch}: val_loss={loss:.2f} (new best ‚¨áÔ∏è)\")\n",
    "        else:\n",
    "            print(f\"Epoch{epoch} : val_loss ={loss:.2f} (improved by {improvement:.3f}\")\n",
    "    else:\n",
    "        epochs_no_improvement+=1\n",
    "        print(f\"Epoch {epoch}: val_loss={loss:.4f} \"\n",
    "              f\"(improved by {improvement:.4f} ‚û°Ô∏è \"\n",
    "              f\"patience {epochs_no_improvement}/{patience})\")\n",
    "        if epochs_no_improvement>=patience:\n",
    "            print(f\"\\nüõë Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "        \n",
    "    \n",
    "    # Check if improvement is significant (>= min_delta)\n",
    "    # Update counters and best_loss\n",
    "    # Print status\n",
    "    # Check early stopping condition\n",
    "    \n",
    "\n",
    "\n",
    "#\n",
    "# Expected output:\n",
    "# Epoch 1: val_loss=0.8560 (new best ‚¨áÔ∏è)\n",
    "# Epoch 2: val_loss=0.7340 (improved by 0.1220 ‚¨áÔ∏è)\n",
    "# Epoch 3: val_loss=0.6510 (improved by 0.0830 ‚¨áÔ∏è)\n",
    "# Epoch 4: val_loss=0.6020 (improved by 0.0490 ‚¨áÔ∏è)\n",
    "# Epoch 5: val_loss=0.5780 (improved by 0.0240 ‚¨áÔ∏è)\n",
    "# Epoch 6: val_loss=0.5650 (improved by 0.0130 ‚¨áÔ∏è)\n",
    "# Epoch 7: val_loss=0.5590 (improved by 0.0060 ‚û°Ô∏è patience 1/3)\n",
    "# Epoch 8: val_loss=0.5560 (improved by 0.0030 ‚û°Ô∏è patience 2/3)\n",
    "# Epoch 9: val_loss=0.5550 (improved by 0.0010 ‚û°Ô∏è patience 3/3)\n",
    "# üõë Early stopping triggered at epoch 9\n",
    "# Best validation loss: 0.5650 (epoch 6)\n",
    "# Saved 5 epochs of unnecessary training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056d5d8",
   "metadata": {},
   "source": [
    "Exercise 3: Cross-Validation Fold Generator (30 min)\n",
    "MLE Context: K-fold cross-validation for robust model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35591dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "validation [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "training [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "validation [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "training [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "validation [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
      "training [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "validation [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]\n",
      "training [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 99]\n",
      "validation [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]\n"
     ]
    }
   ],
   "source": [
    "# Dataset indices\n",
    "dataset_size = 100\n",
    "k_folds = 5\n",
    "\n",
    "# YOUR TASK:\n",
    "# Generate k-fold cross-validation splits:\n",
    "# 1. Divide dataset into k equal folds (or as equal as possible)\n",
    "# 2. For each fold:\n",
    "#    - That fold becomes validation set\n",
    "#    - All other folds become training set\n",
    "# 3. Print train/val splits for each fold\n",
    "# 4. Ensure no data leakage (no overlap between train/val in same fold)\n",
    "#\n",
    "# Expected output:\n",
    "# Fold 1/5:\n",
    "#   Train indices: [20-99] (80 samples)\n",
    "#   Val indices: [0-19] (20 samples)\n",
    "#\n",
    "# Fold 2/5:\n",
    "#   Train indices: [0-19, 40-99] (80 samples)\n",
    "#   Val indices: [20-39] (20 samples)\n",
    "#\n",
    "# Fold 3/5:\n",
    "#   Train indices: [0-39, 60-99] (80 samples)\n",
    "#   Val indices: [40-59] (20 samples)\n",
    "#\n",
    "# ... etc\n",
    "#\n",
    "# Verification:\n",
    "# ‚úì Each sample used for validation exactly once\n",
    "# ‚úì Each sample used for training exactly 4 times\n",
    "# ‚úì No overlap between train/val in any fold\n",
    "\n",
    "# YOUR CODE:\n",
    "fold_size = dataset_size // k_folds\n",
    "all_indices = list(range(dataset_size))\n",
    "for fold  in range(k_folds):\n",
    "    \n",
    "    start=fold*fold_size\n",
    "    end=min(start+fold_size-1,dataset_size)\n",
    "    val_indices=list(range(start,end))\n",
    "    train_indices=[i for i in all_indices if i not in val_indices]\n",
    "    print(f\"training {train_indices}\")\n",
    "    print(f\"validation {val_indices}\")\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d53cad4",
   "metadata": {},
   "source": [
    "DAY 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c04ba",
   "metadata": {},
   "source": [
    "\n",
    "Exercise 1: Feature Scaling (Min-Max Normalization) (20 min)\n",
    "MLE Context: Normalize features to [0, 1] range before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw features (different scales)\n",
    "ages = [25, 45, 32, 67, 19, 54, 38, 29, 51, 41]\n",
    "incomes = [35000, 125000, 67000, 180000, 28000, 95000, 72000, 51000, 110000, 88000]\n",
    "credit_scores = [620, 780, 690, 820, 580, 740, 710, 650, 795, 725]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. For each feature, apply min-max normalization:\n",
    "#    normalized = (value - min) / (max - min)\n",
    "# 2. Create normalized versions of all three lists\n",
    "# 3. Verify all values are in [0, 1] range\n",
    "# 4. Find which samples have ALL features > 0.5 (after normalization)\n",
    "#\n",
    "# Expected output:\n",
    "# Ages - min: 19, max: 67, range: 48\n",
    "# Normalized ages: [0.125, 0.542, 0.271, 1.0, 0.0, 0.729, ...]\n",
    "#\n",
    "# Incomes - min: 28000, max: 180000, range: 152000\n",
    "# Normalized incomes: [0.046, 0.638, 0.257, 1.0, 0.0, 0.441, ...]\n",
    "#\n",
    "# Credit scores - min: 580, max: 820, range: 240\n",
    "# Normalized credit_scores: [0.167, 0.833, 0.458, 1.0, 0.0, ...]\n",
    "#\n",
    "# Samples with ALL features > 0.5:\n",
    "#   Sample 1: age=0.542, income=0.638, credit=0.833 ‚úì\n",
    "#   Sample 3: age=1.0, income=1.0, credit=1.0 ‚úì\n",
    "#   Sample 5: age=0.729, income=0.441, credit=0.667 ‚úó (income too low)\n",
    "\n",
    "# YOUR CODE:\n",
    "def normalize(values):\n",
    "    \"\"\"Min-max normalization to [0, 1]\"\"\"\n",
    "    min_val = min(values)\n",
    "    max_val = max(values)\n",
    "    range_val = max_val - min_val\n",
    "    \n",
    "    # Return list of normalized values\n",
    "    pass\n",
    "\n",
    "normalized_ages = normalize(ages)\n",
    "normalized_incomes = normalize(incomes)\n",
    "normalized_credit_scores = normalize(credit_scores)\n",
    "\n",
    "# Find samples with all features > 0.5\n",
    "high_quality_samples = []\n",
    "for i in range(len(ages)):\n",
    "    # Check if all three normalized features > 0.5\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc7c4a",
   "metadata": {},
   "source": [
    "Exercise 2: Train-Test Split with Stratification (20 min)\n",
    "MLE Context: Split data while preserving class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: features paired with labels\n",
    "X = [  # Features (simplified as single values)\n",
    "    10, 15, 12, 18, 22, 25, 30, 35, 28, 32,\n",
    "    40, 45, 38, 42, 48, 50, 55, 52, 58, 60\n",
    "]\n",
    "\n",
    "y = [  # Labels (binary)\n",
    "    0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
    "    0, 0, 0, 0, 0, 1, 1, 1, 1, 1\n",
    "]\n",
    "# Class distribution: 10 zeros, 10 ones (perfectly balanced)\n",
    "\n",
    "test_size = 0.2  # 20% for testing\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Calculate how many samples for test set (20% of 20 = 4)\n",
    "# 2. To preserve class balance, need 2 zeros and 2 ones in test\n",
    "# 3. Manually create stratified split:\n",
    "#    - Find indices of all class 0 samples\n",
    "#    - Find indices of all class 1 samples\n",
    "#    - Take first 2 from each class for test (simple strategy)\n",
    "#    - Remaining goes to train\n",
    "# 4. Verify class distribution is preserved\n",
    "#\n",
    "# Expected output:\n",
    "# Total samples: 20 (10 class 0, 10 class 1)\n",
    "# Test size: 4 samples\n",
    "#\n",
    "# Test set:\n",
    "#   Indices: [0, 1, 5, 6]\n",
    "#   Features: [10, 15, 25, 30]\n",
    "#   Labels: [0, 0, 1, 1]\n",
    "#   Class distribution: 2 zeros (50%), 2 ones (50%) ‚úì\n",
    "#\n",
    "# Train set:\n",
    "#   Indices: [2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "#   16 samples\n",
    "#   Class distribution: 8 zeros (50%), 8 ones (50%) ‚úì\n",
    "\n",
    "# YOUR CODE:\n",
    "# Find indices for each class\n",
    "class_0_indices = []\n",
    "class_1_indices = []\n",
    "\n",
    "for i, label in enumerate(y):\n",
    "    if label == 0:\n",
    "        class_0_indices.append(i)\n",
    "    else:\n",
    "        class_1_indices.append(i)\n",
    "\n",
    "# Take first 2 from each class for test\n",
    "samples_per_class = 2\n",
    "\n",
    "test_indices = class_0_indices[:samples_per_class] + class_1_indices[:samples_per_class]\n",
    "train_indices = class_0_indices[samples_per_class:] + class_1_indices[samples_per_class:]\n",
    "\n",
    "# Create actual splits\n",
    "X_test = [X[i] for i in test_indices]\n",
    "y_test = [y[i] for i in test_indices]\n",
    "\n",
    "# ... create X_train, y_train\n",
    "\n",
    "# Verify distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a38bc",
   "metadata": {},
   "source": [
    "Exercise 3: Moving Average for Smoothing Training Curves (20 min)\n",
    "MLE Context: Smooth noisy training loss curves for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1979ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw training losses (noisy)\n",
    "losses = [\n",
    "    0.95, 0.89, 0.92, 0.85, 0.82, 0.88, 0.79, 0.75,\n",
    "    0.78, 0.71, 0.73, 0.68, 0.70, 0.65, 0.63, 0.66,\n",
    "    0.61, 0.59, 0.62, 0.58, 0.56, 0.57, 0.54, 0.53\n",
    "]\n",
    "\n",
    "window_size = 3  # Moving average window\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Calculate moving average with window_size=3\n",
    "#    For each position i, average losses[i-1], losses[i], losses[i+1]\n",
    "#    (For edges, use available values)\n",
    "# 2. Compare original vs smoothed\n",
    "# 3. Calculate how much noise was reduced (variance before/after)\n",
    "#\n",
    "# Expected output:\n",
    "# Original losses (first 10): [0.95, 0.89, 0.92, 0.85, 0.82, ...]\n",
    "# Smoothed losses (first 10): [0.92, 0.92, 0.887, 0.863, 0.850, ...]\n",
    "#\n",
    "# Noise reduction:\n",
    "#   Original variance: 0.0234\n",
    "#   Smoothed variance: 0.0198\n",
    "#   Reduction: 15.4%\n",
    "\n",
    "# YOUR CODE:\n",
    "smoothed_losses = []\n",
    "\n",
    "for i in range(len(losses)):\n",
    "    # Determine window boundaries\n",
    "    start = max(0, i - window_size // 2)\n",
    "    end = min(len(losses), i + window_size // 2 + 1)\n",
    "    \n",
    "    # Calculate average of window\n",
    "    window = losses[start:end]\n",
    "    avg = sum(window) / len(window)\n",
    "    smoothed_losses.append(avg)\n",
    "\n",
    "# Calculate variance (simple version: average of squared differences from mean)\n",
    "def calculate_variance(values):\n",
    "    mean = sum(values) / len(values)\n",
    "    squared_diffs = [(x - mean) ** 2 for x in values]\n",
    "    return sum(squared_diffs) / len(squared_diffs)\n",
    "\n",
    "original_var = calculate_variance(losses)\n",
    "smoothed_var = calculate_variance(smoothed_losses)\n",
    "\n",
    "# Print comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2861f",
   "metadata": {},
   "source": [
    "DAY 4: Dictionaries & Sets (75 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbced16",
   "metadata": {},
   "source": [
    "Exercise 1: Hyperparameter Experiment Tracker (25 min)\n",
    "MLE Context: Track and compare multiple experiment runs with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment results\n",
    "experiments = [\n",
    "    {\"id\": \"exp_001\", \"lr\": 0.001, \"batch_size\": 32, \"optimizer\": \"adam\", \"val_acc\": 0.847, \"train_time\": 120},\n",
    "    {\"id\": \"exp_002\", \"lr\": 0.01, \"batch_size\": 32, \"optimizer\": \"adam\", \"val_acc\": 0.823, \"train_time\": 118},\n",
    "    {\"id\": \"exp_003\", \"lr\": 0.001, \"batch_size\": 64, \"optimizer\": \"adam\", \"val_acc\": 0.856, \"train_time\": 95},\n",
    "    {\"id\": \"exp_004\", \"lr\": 0.001, \"batch_size\": 32, \"optimizer\": \"sgd\", \"val_acc\": 0.812, \"train_time\": 115},\n",
    "    {\"id\": \"exp_005\", \"lr\": 0.01, \"batch_size\": 64, \"optimizer\": \"adam\", \"val_acc\": 0.834, \"train_time\": 92},\n",
    "    {\"id\": \"exp_006\", \"lr\": 0.001, \"batch_size\": 64, \"optimizer\": \"sgd\", \"val_acc\": 0.829, \"train_time\": 90},\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Group experiments by optimizer\n",
    "# 2. For each optimizer, calculate average validation accuracy\n",
    "# 3. Find best experiment overall (highest val_acc)\n",
    "# 4. Find best experiment for each optimizer\n",
    "# 5. Analyze: Does larger batch_size always train faster?\n",
    "#\n",
    "# Expected output:\n",
    "# Experiments by optimizer:\n",
    "#   adam: 4 experiments, avg val_acc: 0.840\n",
    "#   sgd: 2 experiments, avg val_acc: 0.8205\n",
    "#\n",
    "# Best overall: exp_003 (val_acc: 0.856, lr=0.001, batch_size=64, optimizer=adam)\n",
    "# Best adam: exp_003 (val_acc: 0.856)\n",
    "# Best sgd: exp_006 (val_acc: 0.829)\n",
    "#\n",
    "# Batch size analysis:\n",
    "#   batch_size=32: avg train_time=117.67s\n",
    "#   batch_size=64: avg train_time=92.33s\n",
    "#   Conclusion: Larger batch size IS faster ‚úì\n",
    "\n",
    "# YOUR CODE:\n",
    "# Group by optimizer\n",
    "optimizer_groups = {}\n",
    "\n",
    "for exp in experiments:\n",
    "    opt = exp[\"optimizer\"]\n",
    "    if opt not in optimizer_groups:\n",
    "        optimizer_groups[opt] = []\n",
    "    optimizer_groups[opt].append(exp)\n",
    "\n",
    "# Calculate averages per optimizer\n",
    "# Find best experiments\n",
    "# Analyze batch size impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63adb2f2",
   "metadata": {},
   "source": [
    "Exercise 2: Feature Importance Consensus (25 min)\n",
    "MLE Context: Multiple models rank features differently. Find consensus features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three different model runs, each gives top features with importance scores\n",
    "model1_features = {\n",
    "    \"age\": 0.25,\n",
    "    \"income\": 0.22,\n",
    "    \"credit_score\": 0.18,\n",
    "    \"employment_years\": 0.15,\n",
    "    \"loan_amount\": 0.12,\n",
    "    \"debt_ratio\": 0.08\n",
    "}\n",
    "\n",
    "model2_features = {\n",
    "    \"income\": 0.28,\n",
    "    \"credit_score\": 0.24,\n",
    "    \"age\": 0.19,\n",
    "    \"loan_amount\": 0.14,\n",
    "    \"num_accounts\": 0.10,\n",
    "    \"debt_ratio\": 0.05\n",
    "}\n",
    "\n",
    "model3_features = {\n",
    "    \"credit_score\": 0.30,\n",
    "    \"income\": 0.25,\n",
    "    \"employment_years\": 0.18,\n",
    "    \"age\": 0.12,\n",
    "    \"loan_amount\": 0.10,\n",
    "    \"payment_history\": 0.05\n",
    "}\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Find features that appear in ALL models (intersection)\n",
    "# 2. Find features that appear in ANY model (union)\n",
    "# 3. For common features, calculate average importance across models\n",
    "# 4. Rank all features by average importance (handle features not in all models)\n",
    "# 5. Identify \"stable\" features (appear in all models with importance > 0.15)\n",
    "#\n",
    "# Expected output:\n",
    "# Features in ALL models: {'age', 'income', 'credit_score', 'loan_amount', 'debt_ratio'}\n",
    "# Features in ANY model: {'age', 'income', 'credit_score', 'employment_years', \n",
    "#                          'loan_amount', 'debt_ratio', 'num_accounts', 'payment_history'}\n",
    "#\n",
    "# Average importance (for features in all models):\n",
    "#   credit_score: 0.24 (model1: 0.18, model2: 0.24, model3: 0.30)\n",
    "#   income: 0.25 (model1: 0.22, model2: 0.28, model3: 0.25)\n",
    "#   age: 0.187 (model1: 0.25, model2: 0.19, model3: 0.12)\n",
    "#   loan_amount: 0.12 (model1: 0.12, model2: 0.14, model3: 0.10)\n",
    "#   debt_ratio: 0.067 (model1: 0.08, model2: 0.05, model3: N/A... wait, need to handle)\n",
    "#\n",
    "# Stable features (in all models, avg > 0.15): income, credit_score, age\n",
    "# Recommendation: Focus on these 3 features for model simplification\n",
    "\n",
    "# YOUR CODE:\n",
    "# Get all feature sets\n",
    "features1 = set(model1_features.keys())\n",
    "features2 = set(model2_features.keys())\n",
    "features3 = set(model3_features.keys())\n",
    "\n",
    "# Intersection and union\n",
    "common_features = features1 & features2 & features3\n",
    "all_features = features1 | features2 | features3\n",
    "\n",
    "# Calculate average importance\n",
    "feature_avg_importance = {}\n",
    "\n",
    "for feature in all_features:\n",
    "    importances = []\n",
    "    if feature in model1_features:\n",
    "        importances.append(model1_features[feature])\n",
    "    if feature in model2_features:\n",
    "        importances.append(model2_features[feature])\n",
    "    if feature in model3_features:\n",
    "        importances.append(model3_features[feature])\n",
    "    \n",
    "    avg = sum(importances) / len(importances)\n",
    "    feature_avg_importance[feature] = avg\n",
    "\n",
    "# Sort by importance\n",
    "# Identify stable features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a663d",
   "metadata": {},
   "source": [
    "Exercise 3: Dataset Deduplication with Hash-Based Detection (25 min)\n",
    "MLE Context: Remove duplicate samples from training data (critical preprocessing step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training samples (some are duplicates)\n",
    "samples = [\n",
    "    {\"text\": \"machine learning is great\", \"label\": 1, \"source\": \"tweet\"},\n",
    "    {\"text\": \"python programming\", \"label\": 0, \"source\": \"article\"},\n",
    "    {\"text\": \"machine learning is great\", \"label\": 1, \"source\": \"blog\"},  # Duplicate text, different source\n",
    "    {\"text\": \"deep learning basics\", \"label\": 1, \"source\": \"tutorial\"},\n",
    "    {\"text\": \"python programming\", \"label\": 0, \"source\": \"article\"},  # Exact duplicate\n",
    "    {\"text\": \"data science tips\", \"label\": 0, \"source\": \"blog\"},\n",
    "    {\"text\": \"machine learning is great\", \"label\": 0, \"source\": \"tweet\"},  # Same text, DIFFERENT label! ‚ö†Ô∏è\n",
    "    {\"text\": \"deep learning basics\", \"label\": 1, \"source\": \"course\"},  # Duplicate text\n",
    "]\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Remove exact duplicates (all fields identical)\n",
    "# 2. Identify duplicate texts with SAME label (keep first occurrence)\n",
    "# 3. Identify duplicate texts with DIFFERENT labels (critical data quality issue!)\n",
    "# 4. Track: text -> set of labels seen\n",
    "# 5. Generate deduplication report\n",
    "#\n",
    "# Expected output:\n",
    "# Original dataset: 8 samples\n",
    "#\n",
    "# Deduplication analysis:\n",
    "#   Exact duplicates found: 1 (sample 4 matches sample 1)\n",
    "#   Text duplicates (same label): 2 \n",
    "#     - \"machine learning is great\" (label 1): appears 2 times\n",
    "#     - \"deep learning basics\" (label 1): appears 2 times\n",
    "#   \n",
    "#   ‚ö†Ô∏è CRITICAL: Text with conflicting labels: 1\n",
    "#     - \"machine learning is great\": labels {0, 1}\n",
    "#       Sample 0: label=1, source=tweet\n",
    "#       Sample 2: label=1, source=blog\n",
    "#       Sample 6: label=0, source=tweet ‚ö†Ô∏è\n",
    "#\n",
    "# After deduplication: 5 unique samples\n",
    "# Samples removed: 3\n",
    "# Samples requiring manual review: 1 (conflicting labels)\n",
    "#\n",
    "# Clean dataset:\n",
    "#   {\"text\": \"machine learning is great\", \"label\": 1, \"source\": \"tweet\"}\n",
    "#   {\"text\": \"python programming\", \"label\": 0, \"source\": \"article\"}\n",
    "#   {\"text\": \"deep learning basics\", \"label\": 1, \"source\": \"tutorial\"}\n",
    "#   {\"text\": \"data science tips\", \"label\": 0, \"source\": \"blog\"}\n",
    "#   Note: Excluded \"machine learning is great\" with label=0 due to conflict\n",
    "\n",
    "# YOUR CODE:\n",
    "# Track what we've seen\n",
    "seen_exact = set()  # For exact duplicates\n",
    "text_to_labels = {}  # Track all labels per text\n",
    "text_to_samples = {}  # Track all samples per text\n",
    "unique_samples = []\n",
    "exact_duplicates = []\n",
    "conflicting_samples = []\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "    # Create hashable representation for exact duplicate detection\n",
    "    # Hint: Convert dict to sorted tuple of items\n",
    "    exact_key = tuple(sorted(sample.items()))\n",
    "    \n",
    "    # Check for exact duplicate\n",
    "    if exact_key in seen_exact:\n",
    "        exact_duplicates.append(idx)\n",
    "        continue\n",
    "    \n",
    "    seen_exact.add(exact_key)\n",
    "    \n",
    "    # Track text and labels\n",
    "    text = sample[\"text\"]\n",
    "    label = sample[\"label\"]\n",
    "    \n",
    "    if text not in text_to_labels:\n",
    "        text_to_labels[text] = set()\n",
    "        text_to_samples[text] = []\n",
    "    \n",
    "    text_to_labels[text].add(label)\n",
    "    text_to_samples[text].append((idx, sample))\n",
    "\n",
    "# Now process: keep first occurrence of each text, but flag conflicts\n",
    "for text, label_set in text_to_labels.items():\n",
    "    samples_for_text = text_to_samples[text]\n",
    "    \n",
    "    if len(label_set) > 1:\n",
    "        # Conflicting labels!\n",
    "        conflicting_samples.append({\n",
    "            \"text\": text,\n",
    "            \"labels\": label_set,\n",
    "            \"samples\": samples_for_text\n",
    "        })\n",
    "        # Skip this text entirely (needs manual review)\n",
    "    else:\n",
    "        # Keep first occurrence\n",
    "        unique_samples.append(samples_for_text[0][1])\n",
    "\n",
    "# Print detailed report\n",
    "print(f\"Original dataset: {len(samples)} samples\\n\")\n",
    "print(\"Deduplication analysis:\")\n",
    "print(f\"  Exact duplicates found: {len(exact_duplicates)}\")\n",
    "\n",
    "# Count text duplicates with same label\n",
    "text_dup_count = sum(1 for text, samples in text_to_samples.items() \n",
    "                     if len(samples) > 1 and len(text_to_labels[text]) == 1)\n",
    "print(f\"  Text duplicates (same label): {text_dup_count}\")\n",
    "\n",
    "# Report conflicts\n",
    "if conflicting_samples:\n",
    "    print(f\"\\n  ‚ö†Ô∏è CRITICAL: Texts with conflicting labels: {len(conflicting_samples)}\")\n",
    "    for conflict in conflicting_samples:\n",
    "        print(f\"    - \\\"{conflict['text']}\\\": labels {conflict['labels']}\")\n",
    "        for idx, sample in conflict['samples']:\n",
    "            print(f\"      Sample {idx}: label={sample['label']}, source={sample['source']}\")\n",
    "\n",
    "print(f\"\\nAfter deduplication: {len(unique_samples)} unique samples\")\n",
    "print(f\"Samples removed: {len(samples) - len(unique_samples)}\")\n",
    "print(f\"Samples requiring manual review: {len(conflicting_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83216868",
   "metadata": {},
   "source": [
    "DAY 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876f359",
   "metadata": {},
   "source": [
    "Exercise 1: Comprehensive Metrics Library (30 min)\n",
    "MLE Context: Build reusable evaluation functions that work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad15680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TASK: Implement these functions for binary classification metrics\n",
    "\n",
    "def calculate_confusion_matrix(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate TP, TN, FP, FN from predictions and labels.\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of binary predictions [0, 1, 1, ...]\n",
    "        labels: List of true labels [0, 1, 0, ...]\n",
    "    \n",
    "    Returns:\n",
    "        Dict: {\"tp\": int, \"tn\": int, \"fp\": int, \"fn\": int}\n",
    "    \n",
    "    Example:\n",
    "        >>> calculate_confusion_matrix([1, 0, 1, 0], [1, 0, 0, 0])\n",
    "        {\"tp\": 1, \"tn\": 2, \"fp\": 1, \"fn\": 0}\n",
    "    \"\"\"\n",
    "    tp = tn = fp = fn = 0\n",
    "    \n",
    "    for pred, label in zip(predictions, labels):\n",
    "        # Your logic here\n",
    "        pass\n",
    "    \n",
    "    return {\"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn}\n",
    "\n",
    "\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    Returns:\n",
    "        Float: Accuracy between 0 and 1\n",
    "    \"\"\"\n",
    "    cm = calculate_confusion_matrix(predictions, labels)\n",
    "    # Use confusion matrix to calculate accuracy\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate_precision(predictions, labels):\n",
    "    \"\"\"\n",
    "    Precision = TP / (TP + FP)\n",
    "    Measures: Of all positive predictions, how many were correct?\n",
    "    \n",
    "    Returns:\n",
    "        Float: Precision, or None if no positive predictions\n",
    "    \"\"\"\n",
    "    cm = calculate_confusion_matrix(predictions, labels)\n",
    "    \n",
    "    if cm[\"tp\"] + cm[\"fp\"] == 0:\n",
    "        return None  # No positive predictions\n",
    "    \n",
    "    # Calculate precision\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate_recall(predictions, labels):\n",
    "    \"\"\"\n",
    "    Recall = TP / (TP + FN)\n",
    "    Measures: Of all actual positives, how many did we find?\n",
    "    \n",
    "    Returns:\n",
    "        Float: Recall, or None if no actual positives\n",
    "    \"\"\"\n",
    "    # Your code\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate_f1_score(predictions, labels):\n",
    "    \"\"\"\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    Harmonic mean of precision and recall.\n",
    "    \n",
    "    Returns:\n",
    "        Float: F1 score, or None if can't calculate\n",
    "    \"\"\"\n",
    "    precision = calculate_precision(predictions, labels)\n",
    "    recall = calculate_recall(predictions, labels)\n",
    "    \n",
    "    if precision is None or recall is None:\n",
    "        return None\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate F1\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate_specificity(predictions, labels):\n",
    "    \"\"\"\n",
    "    Specificity = TN / (TN + FP)\n",
    "    Measures: Of all actual negatives, how many did we correctly identify?\n",
    "    \n",
    "    Returns:\n",
    "        Float: Specificity\n",
    "    \"\"\"\n",
    "    # Your code\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate_model_comprehensive(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate ALL metrics and return organized report.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with structure:\n",
    "        {\n",
    "            \"confusion_matrix\": {...},\n",
    "            \"primary_metrics\": {\"accuracy\": float, \"f1\": float},\n",
    "            \"precision_recall\": {\"precision\": float, \"recall\": float},\n",
    "            \"specificity\": float,\n",
    "            \"class_distribution\": {\"predicted_positive\": int, \"actual_positive\": int}\n",
    "        }\n",
    "    \"\"\"\n",
    "    cm = calculate_confusion_matrix(predictions, labels)\n",
    "    \n",
    "    report = {\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"primary_metrics\": {\n",
    "            \"accuracy\": calculate_accuracy(predictions, labels),\n",
    "            \"f1\": calculate_f1_score(predictions, labels)\n",
    "        },\n",
    "        \"precision_recall\": {\n",
    "            \"precision\": calculate_precision(predictions, labels),\n",
    "            \"recall\": calculate_recall(predictions, labels)\n",
    "        },\n",
    "        \"specificity\": calculate_specificity(predictions, labels),\n",
    "        \"class_distribution\": {\n",
    "            \"predicted_positive\": sum(predictions),\n",
    "            \"actual_positive\": sum(labels),\n",
    "            \"predicted_negative\": len(predictions) - sum(predictions),\n",
    "            \"actual_negative\": len(labels) - sum(labels)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "# TEST YOUR FUNCTIONS:\n",
    "test_predictions = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
    "test_labels =      [1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n",
    "\n",
    "report = evaluate_model_comprehensive(test_predictions, test_labels)\n",
    "\n",
    "print(\"=== Model Evaluation Report ===\")\n",
    "print(f\"Confusion Matrix: {report['confusion_matrix']}\")\n",
    "print(f\"Accuracy: {report['primary_metrics']['accuracy']:.3f}\")\n",
    "print(f\"F1 Score: {report['primary_metrics']['f1']:.3f}\")\n",
    "print(f\"Precision: {report['precision_recall']['precision']:.3f}\")\n",
    "print(f\"Recall: {report['precision_recall']['recall']:.3f}\")\n",
    "print(f\"Specificity: {report['specificity']:.3f}\")\n",
    "print(f\"Class Distribution: {report['class_distribution']}\")\n",
    "\n",
    "# Expected output (approximately):\n",
    "# Confusion Matrix: {'tp': 5, 'tn': 3, 'fp': 2, 'fn': 2}\n",
    "# Accuracy: 0.667\n",
    "# F1 Score: 0.714\n",
    "# Precision: 0.714\n",
    "# Recall: 0.714\n",
    "# Specificity: 0.600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3f655",
   "metadata": {},
   "source": [
    "Exercise 2: Data Preprocessing Pipeline (25 min)\n",
    "MLE Context: Build modular cleaning functions for production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text: lowercase, strip whitespace, remove extra spaces.\n",
    "    \n",
    "    Args:\n",
    "        text: String or None\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned string, or None if invalid input\n",
    "    \n",
    "    Example:\n",
    "        >>> clean_text(\"  HELLO   World  \")\n",
    "        \"hello world\"\n",
    "    \"\"\"\n",
    "    if text is None or not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    # Clean and return\n",
    "    # Hint: strip(), lower(), and handle multiple spaces\n",
    "    pass\n",
    "\n",
    "\n",
    "def parse_numeric(value, value_type=\"int\"):\n",
    "    \"\"\"\n",
    "    Parse string to numeric value with validation.\n",
    "    \n",
    "    Args:\n",
    "        value: String, int, or float\n",
    "        value_type: \"int\" or \"float\"\n",
    "    \n",
    "    Returns:\n",
    "        Parsed number, or None if invalid\n",
    "    \n",
    "    Example:\n",
    "        >>> parse_numeric(\"123\", \"int\")\n",
    "        123\n",
    "        >>> parse_numeric(\"12.5\", \"float\")\n",
    "        12.5\n",
    "        >>> parse_numeric(\"abc\", \"int\")\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Handle already numeric\n",
    "    if isinstance(value, (int, float)):\n",
    "        if value_type == \"int\":\n",
    "            return int(value)\n",
    "        return float(value)\n",
    "    \n",
    "    # Try to parse string\n",
    "    # Handle exceptions\n",
    "    pass\n",
    "\n",
    "\n",
    "def validate_range(value, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Check if value is within valid range.\n",
    "    \n",
    "    Returns:\n",
    "        value if valid, None if out of range\n",
    "    \n",
    "    Example:\n",
    "        >>> validate_range(25, 0, 100)\n",
    "        25\n",
    "        >>> validate_range(-5, 0, 100)\n",
    "        None\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def extract_price(price_string):\n",
    "    \"\"\"\n",
    "    Extract numeric price from string.\n",
    "    Handle: \"$50.00\", \"50\", \"$1,234.56\", \"‚Ç¨45.99\"\n",
    "    \n",
    "    Returns:\n",
    "        Float price, or None if can't parse\n",
    "    \n",
    "    Example:\n",
    "        >>> extract_price(\"$1,234.56\")\n",
    "        1234.56\n",
    "        >>> extract_price(\"‚Ç¨45.99\")\n",
    "        45.99\n",
    "    \"\"\"\n",
    "    if not isinstance(price_string, str):\n",
    "        return parse_numeric(price_string, \"float\")\n",
    "    \n",
    "    # Remove currency symbols and commas\n",
    "    cleaned = price_string\n",
    "    for char in ['$', '‚Ç¨', '¬£', ',']:\n",
    "        cleaned = cleaned.replace(char, '')\n",
    "    \n",
    "    # Parse as float\n",
    "    pass\n",
    "\n",
    "\n",
    "def clean_and_validate_record(record, schema):\n",
    "    \"\"\"\n",
    "    Clean entire record based on schema definition.\n",
    "    \n",
    "    Args:\n",
    "        record: Dict with raw data\n",
    "        schema: Dict defining field types and validation\n",
    "            Example: {\n",
    "                \"name\": {\"type\": \"text\", \"required\": True},\n",
    "                \"age\": {\"type\": \"int\", \"min\": 0, \"max\": 120},\n",
    "                \"price\": {\"type\": \"price\", \"min\": 0}\n",
    "            }\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (cleaned_record, errors)\n",
    "        - cleaned_record: Dict with cleaned data, or None if critical errors\n",
    "        - errors: List of error messages\n",
    "    \n",
    "    Example:\n",
    "        >>> schema = {\n",
    "        ...     \"name\": {\"type\": \"text\", \"required\": True},\n",
    "        ...     \"age\": {\"type\": \"int\", \"min\": 0, \"max\": 120}\n",
    "        ... }\n",
    "        >>> clean_and_validate_record(\n",
    "        ...     {\"name\": \"  Alice  \", \"age\": \"25\"},\n",
    "        ...     schema\n",
    "        ... )\n",
    "        ({\"name\": \"alice\", \"age\": 25}, [])\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    errors = []\n",
    "    \n",
    "    for field_name, field_schema in schema.items():\n",
    "        field_type = field_schema.get(\"type\")\n",
    "        required = field_schema.get(\"required\", False)\n",
    "        \n",
    "        # Get raw value\n",
    "        raw_value = record.get(field_name)\n",
    "        \n",
    "        # Check if required field is missing\n",
    "        if required and (raw_value is None or raw_value == \"\"):\n",
    "            errors.append(f\"{field_name}: required field missing\")\n",
    "            continue\n",
    "        \n",
    "        # Clean based on type\n",
    "        if field_type == \"text\":\n",
    "            cleaned_value = clean_text(raw_value)\n",
    "        elif field_type == \"int\":\n",
    "            cleaned_value = parse_numeric(raw_value, \"int\")\n",
    "            if cleaned_value is not None:\n",
    "                # Validate range if specified\n",
    "                min_val = field_schema.get(\"min\")\n",
    "                max_val = field_schema.get(\"max\")\n",
    "                if min_val is not None or max_val is not None:\n",
    "                    cleaned_value = validate_range(\n",
    "                        cleaned_value, \n",
    "                        min_val if min_val is not None else float('-inf'),\n",
    "                        max_val if max_val is not None else float('inf')\n",
    "                    )\n",
    "        elif field_type == \"float\":\n",
    "            cleaned_value = parse_numeric(raw_value, \"float\")\n",
    "        elif field_type == \"price\":\n",
    "            cleaned_value = extract_price(raw_value)\n",
    "            if cleaned_value is not None:\n",
    "                min_val = field_schema.get(\"min\", 0)\n",
    "                if cleaned_value < min_val:\n",
    "                    cleaned_value = None\n",
    "        else:\n",
    "            cleaned_value = raw_value\n",
    "        \n",
    "        # Track errors\n",
    "        if cleaned_value is None and raw_value is not None:\n",
    "            errors.append(f\"{field_name}: invalid value '{raw_value}'\")\n",
    "        else:\n",
    "            cleaned[field_name] = cleaned_value\n",
    "    \n",
    "    # Return None if critical errors (missing required fields)\n",
    "    if any(\"required field missing\" in e for e in errors):\n",
    "        return None, errors\n",
    "    \n",
    "    return cleaned, errors\n",
    "\n",
    "\n",
    "# TEST DATA:\n",
    "schema = {\n",
    "    \"name\": {\"type\": \"text\", \"required\": True},\n",
    "    \"age\": {\"type\": \"int\", \"min\": 18, \"max\": 100},\n",
    "    \"income\": {\"type\": \"price\", \"min\": 0},\n",
    "    \"email\": {\"type\": \"text\", \"required\": True}\n",
    "}\n",
    "\n",
    "test_records = [\n",
    "    {\"name\": \"  Alice Smith  \", \"age\": \"25\", \"income\": \"$50,000\", \"email\": \"alice@example.com\"},\n",
    "    {\"name\": \"Bob\", \"age\": \"17\", \"income\": \"$60,000\", \"email\": \"bob@example.com\"},  # Age too young\n",
    "    {\"name\": \"Charlie\", \"age\": \"invalid\", \"income\": \"$70k\", \"email\": \"charlie@example.com\"},  # Invalid age\n",
    "    {\"name\": \"\", \"age\": \"30\", \"income\": \"$80,000\", \"email\": \"\"},  # Missing required fields\n",
    "]\n",
    "\n",
    "cleaned_records = []\n",
    "failed_records = []\n",
    "\n",
    "for idx, record in enumerate(test_records):\n",
    "    cleaned, errors = clean_and_validate_record(record, schema)\n",
    "    \n",
    "    if cleaned:\n",
    "        cleaned_records.append(cleaned)\n",
    "        if errors:\n",
    "            print(f\"Record {idx}: Cleaned with warnings: {errors}\")\n",
    "    else:\n",
    "        failed_records.append((record, errors))\n",
    "        print(f\"Record {idx}: Failed - {errors}\")\n",
    "\n",
    "print(f\"\\nSuccessfully cleaned: {len(cleaned_records)}/{len(test_records)} records\")\n",
    "print(f\"Failed: {len(failed_records)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee4e12",
   "metadata": {},
   "source": [
    "Exercise 3: Feature Engineering Function Suite (20 min)\n",
    "MLE Context: Create reusable feature extraction functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9929eef",
   "metadata": {},
   "source": [
    "def extract_text_features(text):\n",
    "    \"\"\"\n",
    "    Extract features from text for ML model.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with keys:\n",
    "        - word_count: Number of words\n",
    "        - char_count: Number of characters (excluding spaces)\n",
    "        - avg_word_length: Average word length\n",
    "        - uppercase_ratio: Ratio of uppercase letters\n",
    "        - digit_count: Number of digits\n",
    "        - special_char_count: Number of special characters (!?.,;:)\n",
    "    \n",
    "    Example:\n",
    "        >>> extract_text_features(\"Hello World! 123\")\n",
    "        {\n",
    "            \"word_count\": 3,\n",
    "            \"char_count\": 13,\n",
    "            \"avg_word_length\": 4.33,\n",
    "            \"uppercase_ratio\": 0.154,\n",
    "            \"digit_count\": 3,\n",
    "            \"special_char_count\": 1\n",
    "        }\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Your code here\n",
    "    # Hint: text.split() for words, iterate chars for counting\n",
    "    pass\n",
    "\n",
    "\n",
    "def create_time_features(timestamp_hour, day_of_week):\n",
    "    \"\"\"\n",
    "    Create time-based categorical features.\n",
    "    \n",
    "    Args:\n",
    "        timestamp_hour: Hour of day (0-23)\n",
    "        day_of_week: Day (0=Monday, 6=Sunday)\n",
    "    \n",
    "    Returns:\n",
    "        Dict with keys:\n",
    "        - is_weekend: Boolean\n",
    "        - is_business_hours: Boolean (9-17, Mon-Fri)\n",
    "        - time_of_day: \"night\"(0-6), \"morning\"(6-12), \"afternoon\"(12-18), \"evening\"(18-24)\n",
    "        - is_peak_hours: Boolean (8-10, 17-19 on weekdays)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def normalize_features(value, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Min-max normalization to [0, 1].\n",
    "    \n",
    "    Returns:\n",
    "        Float between 0 and 1, or None if invalid range\n",
    "    \"\"\"\n",
    "    if max_val == min_val:\n",
    "        return None  # Cannot normalize\n",
    "    \n",
    "    # Formula: (value - min) / (max - min)\n",
    "    pass\n",
    "\n",
    "\n",
    "def create_interaction_features(feature1, feature2):\n",
    "    \"\"\"\n",
    "    Create interaction features between two numeric features.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with keys:\n",
    "        - product: feature1 * feature2\n",
    "        - ratio: feature1 / feature2 (or None if feature2 is 0)\n",
    "        - difference: feature1 - feature2\n",
    "        - sum: feature1 + feature2\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def engineer_features(raw_data, feature_config):\n",
    "    \"\"\"\n",
    "    Apply all feature engineering based on config.\n",
    "    \n",
    "    Args:\n",
    "        raw_data: Dict with raw fields\n",
    "        feature_config: Dict specifying which features to create\n",
    "            Example: {\n",
    "                \"text_features\": {\"field\": \"description\"},\n",
    "                \"time_features\": {\"hour\": \"timestamp_hour\", \"day\": \"day_of_week\"},\n",
    "                \"normalize\": [\n",
    "                    {\"field\": \"price\", \"min\": 0, \"max\": 1000}\n",
    "                ],\n",
    "                \"interactions\": [\n",
    "                    {\"f1\": \"age\", \"f2\": \"income\"}\n",
    "                ]\n",
    "            }\n",
    "    \n",
    "    Returns:\n",
    "        Dict with all engineered features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Extract text features if configured\n",
    "    if \"text_features\" in feature_config:\n",
    "        text_field = feature_config[\"text_features\"][\"field\"]\n",
    "        text = raw_data.get(text_field)\n",
    "        if text:\n",
    "            text_feats = extract_text_features(text)\n",
    "            if text_feats:\n",
    "                features.update(text_feats)\n",
    "    \n",
    "    # Create time features if configured\n",
    "    if \"time_features\" in feature_config:\n",
    "        hour = raw_data.get(feature_config[\"time_features\"][\"hour\"])\n",
    "        day = raw_data.get(feature_config[\"time_features\"][\"day\"])\n",
    "        if hour is not None and day is not None:\n",
    "            time_feats = create_time_features(hour, day)\n",
    "            features.update(time_feats)\n",
    "    \n",
    "    # Normalize features if configured\n",
    "    # Create interactions if configured\n",
    "    # ... your code\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# TEST:\n",
    "raw_sample = {\n",
    "    \"description\": \"Great product! Very satisfied with purchase.\",\n",
    "    \"timestamp_hour\": 14,\n",
    "    \"day_of_week\": 2,  # Wednesday\n",
    "    \"price\": 199.99,\n",
    "    \"age\": 35,\n",
    "    \"income\": 75000\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"text_features\": {\"field\": \"description\"},\n",
    "    \"time_features\": {\"hour\": \"timestamp_hour\", \"day\": \"day_of_week\"},\n",
    "    \"normalize\": [\n",
    "        {\"field\": \"price\", \"min\": 0, \"max\": 500}\n",
    "    ],\n",
    "    \"interactions\": [\n",
    "        {\"f1\": \"age\", \"f2\": \"income\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "features = engineer_features(raw_sample, config)\n",
    "print(\"Engineered features:\")\n",
    "for key, value in features.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Expected features include:\n",
    "# word_count, char_count, avg_word_length, uppercase_ratio, etc.\n",
    "# is_weekend, is_business_hours, time_of_day, is_peak_hours\n",
    "# normalized_price\n",
    "# age_income_product, age_income_ratio, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ca7ca",
   "metadata": {},
   "source": [
    "WEEK 2: INTERMEDIATE PYTHON (Days 6-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f5f75",
   "metadata": {},
   "source": [
    "DAY 6: List Comprehensions & Lambda Functions (75 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539a8ff",
   "metadata": {},
   "source": [
    "Exercise 1: Vectorized Feature Transformations (20 min)\n",
    "MLE Context: Apply transformations to entire feature columns efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
